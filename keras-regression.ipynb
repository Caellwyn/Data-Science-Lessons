{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow and Keras for Regression\n",
    "\n",
    "## From NumPy to Keras\n",
    "Having embarked on our initial exploration of neural networks through the lens of NumPy, we now stand at the threshold of a more expansive landscape. This lesson marks a pivotal transition, as we introduce Keras, a high-level API that revolutionizes the process of building and training neural networks.\n",
    "\n",
    "### Lesson Outline:\n",
    "1. Introduction to TensorFlow and Keras\n",
    "2. Regression vs. Classification in deep learning\n",
    "3. \n",
    "\n",
    "#### Recalling the Foundations:\n",
    "\n",
    "Our prior endeavors with NumPy provided us with a fundamental understanding of neural network architecture and training dynamics. We witnessed the intricate interplay of layers, transforming inputs into desired outputs, guided by the meticulous steps of forward and backward propagation. This groundwork established a solid foundation upon which we can now build.\n",
    "\n",
    "#### From Building Blocks to Grand Designs:\n",
    "\n",
    "However, while NumPy serves admirably for small-scale exploration, its limitations become apparent as the complexity of our models and datasets increases. Enter TensorFlow, a robust and multifaceted framework specifically designed for tackling such challenges. TensorFlow empowers us to construct and optimize large-scale, intricate models with astonishing efficiency.\n",
    "\n",
    "#### The Power of Tensors:\n",
    "\n",
    "The cornerstone of TensorFlow's architecture lies in tensors, multi-dimensional arrays capable of representing data of diverse shapes and sizes. These dynamic entities flow through the neural network, undergoing transformations at each layer, forming the lifeblood of the computational process. Unlike the linear limitations of NumPy, TensorFlow grants us the freedom to design complex, branched graph structures, paving the way for a vast array of network architectures.\n",
    "\n",
    "#### Keras: The Architectural Facilitator:\n",
    "\n",
    "Yet, this power comes at a cost â€“ navigating the intricacies of TensorFlow directly can be daunting. This is where Keras steps in, acting as a bridge between our architectural vision and the computational might of TensorFlow. Keras offers a concise and intuitive API, akin to Pandas' relationship with NumPy, that streamlines the process of building and training neural networks.\n",
    "\n",
    "#### From Lines of Code to Masterpieces:\n",
    "\n",
    "Through Keras, what once required lengthy passages of low-level TensorFlow code can now be expressed in a few elegant lines. This paradigm shift dramatically reduces both code complexity and development time, empowering us to focus on the core design principles of our models. Moreover, Keras leverages the underlying power of TensorFlow, ensuring efficient training and optimization even for the most ambitious projects.\n",
    "\n",
    "This glimpse into the world of Keras serves as an invitation to delve deeper into its capabilities. In the upcoming lessons, we will explore its intricacies, crafting sophisticated neural networks with unprecedented ease and unlocking the full potential of TensorFlow's computational prowess. Prepare yourselves, fellow explorers, for we are on the cusp of a journey to the frontiers of machine learning, armed with the elegance and efficiency of Keras as our guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Dataset: Neural Networking for Regression\n",
    "\n",
    "### Boston Housing Dataset:\n",
    "\n",
    "In this lesson we will be demonstrating how to fit and evaluate a keras model on the Boston Housing Dataset.  This is a commonly used demonstration dataset describing median prices in several Boston suburbs.  The goal is to use various data about each region to predict the median prices of homes sold there.  The median home values in the target are expressed in 1000s of US Dollars.\n",
    "\n",
    "The data was collected originally by the U.S. Census Service and used in a paper by Harssion and Rubinfield in 1978.  If you would like to know more, you can find details [here](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)\n",
    "\n",
    "\n",
    "### Regression Vs Classification in Neural Networks.\n",
    "\n",
    "In the last lesson we classified iris flowers into one of two different subspecies.  This was an example of classification.  We used a sigmoid activation function on our final layer to force our model to output a number between 0 and 1, representing the probability that a sample belonged to class 1, and the inverse probability of it belonging to class 0.  \n",
    "\n",
    "#### Activation Function: Linear (None)\n",
    "\n",
    "For this dataset we want our model to have the flexibility to output any real number.  This means we would not want to use a limiting activation function such as sigmoid.  Instead, we will use a linear activation, which is the same as the indentity function and equivalent to no activation function for the final layer.  We will, however, use non-linear activation functions on our hidden layer(s) to give our model the ability to find non-linear relationships between the features and target.\n",
    "\n",
    "#### Loss Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets.boston_housing import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
       "        3.96900e+02, 1.87200e+01],\n",
       "       [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
       "        3.95380e+02, 3.11000e+00],\n",
       "       [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        3.75520e+02, 3.26000e+00],\n",
       "       ...,\n",
       "       [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
       "        3.62250e+02, 7.83000e+00],\n",
       "       [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        2.61950e+02, 1.57900e+01],\n",
       "       [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
       "        3.76700e+02, 4.38000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
