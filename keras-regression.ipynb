{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow and Keras for Regression\n",
    "\n",
    "## Introduction\n",
    "In the previous lessons you learned about the structure of neural networks, specifically densely connected feed-forward neural networks, or multi-layer perceptrons (MLPs).  You learned about how information is propagated forward through the network from input to predictions.  You also learned about how a model calculates it's own errors using a loss function, determines the gradient of the loss, and uses that to propagate changes in the network weights backward from end to beginning.  This full forward and backward propagation cycle is called an epoch.  Over many epochs a model gradually reduces its loss and converges toward a better configuration of weights to make better predictions.\n",
    "\n",
    "In this lesson, you will learn about TensorFlow and Keras, two related tools to automate this process and make it more code and computationally efficient.  These tools will make deep learning model development much simpler and faster so you can get powerful models tuned to your data quickly and with fewer opportunities for error.  \n",
    "\n",
    "### Lesson Outline:\n",
    "1. Introduction to TensorFlow and Keras\n",
    "2. Regression vs. Classification in deep learning\n",
    "3. Preparing data for deep learning\n",
    "4. Creating your model architecture, including layers, nodes, activation functions, and loss functions.\n",
    "5. Training your model and visualizing the training history\n",
    "6. Evaluating your Keras model.\n",
    "\n",
    "### TensorFlow\n",
    "\n",
    "TensorFlow is a robust and multifaceted framework specifically designed for deep learning. TensorFlow empowers us to construct and optimize large-scale, intricate models with astonishing efficiency.  The cornerstone of TensorFlow's architecture lies in tensors, multi-dimensional arrays capable of representing data of diverse shapes and sizes. These dynamic entities flow through the neural network, undergoing transformations at each layer, forming the lifeblood of the computational process. TensorFlow grants us the freedom to design complex, branched graph structures, paving the way for a vast array of network architectures.\n",
    "\n",
    "### Keras: Deep Learning Simplified\n",
    "\n",
    "Yet, this power comes at a cost – navigating the intricacies of TensorFlow directly can be daunting. Keras offers a concise and intuitive API, akin to Pandas' relationship with NumPy, that streamlines the process of building and training neural networks.\n",
    "\n",
    "Unlike Pandas, Keras is a unified API that can be run with several backend engines: TensorFlow, Theanos, or PyTorch.  The interface is the same, but Keras can create models in any of these frameworks.  In the following lessons, we will be using a TensorFlow backend for Keras, but just note that, with few adjustments, you could create and deploy models in the other two frameworks as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Keras\n",
    "\n",
    "In this demonstration we will be using Keras 3 with a TensorFlow backend.  In order to get Keras 3 to correctly install, we will first need to install or upgrade to the latest version of tensorflow, then install or upgrade Keras.  This is because TensorFlow will overwrite the Keras version if installed after Keras.\n",
    "\n",
    "At the time of writing, TensorFlow 2.15 is the latest version, and you may get a warning when installing Keras 3.  Don't worry, and this warning should go away once TensorFlow 2.16 is released.\n",
    "\n",
    "See the documentation [here](https://keras.io/getting_started/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install/upgrade TensorFlow\n",
    "# !pip install --upgrade tensorflow\n",
    "## Install or upgrade Keras\n",
    "# !pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.2'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If keras is not showing the correct version, try installing it using your terminal into your virtual environment, the re-adding the kernel to Jupyter through ipykernel.  \n",
    "\n",
    "Try the following in your terminal:\n",
    "\n",
    "`conda activate ENVNAME`\n",
    "\n",
    "`pip install --upgrade tensorflow`\n",
    "\n",
    "`pip install --upgrade keras`\n",
    "\n",
    "`pip install ipykernel`\n",
    "\n",
    "`python -m ipykernel install --user --name ENVNAME --display-name \"Python (whatever you want to call it)\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Dataset: Neural Networking for Regression\n",
    "\n",
    "### Boston Housing Dataset:\n",
    "\n",
    "In this lesson we will be demonstrating how to fit and evaluate a keras model on the Boston Housing Dataset.  This is a commonly used demonstration dataset describing median prices in several Boston suburbs.  The goal is to use various data about each region to predict the median prices of homes sold there.  The median home values in the target are expressed in 1000s of US Dollars.\n",
    "\n",
    "The data was collected originally by the U.S. Census Service and used in a paper by Harssion and Rubinfield in 1978.  If you would like to know more, you can find details [here](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Vs Classification in Neural Networks.\n",
    "\n",
    "In the last lesson we classified iris flowers into one of two different subspecies.  This was an example of classification.  We used a sigmoid activation function on our final layer to force our model to output a number between 0 and 1, representing the probability that a sample belonged to class 1, and the inverse probability of it belonging to class 0.  \n",
    "\n",
    "#### Activation Function: Linear (None)\n",
    "\n",
    "For this dataset we want our model to have the flexibility to output any real number.  This means we would not want to use a limiting activation function such as sigmoid.  Instead, we will use a linear activation, which is the same as the indentity function and equivalent to no activation function for the final layer.  We will, however, use non-linear activation functions on our hidden layer(s) to give our model the ability to find non-linear relationships between the features and target.\n",
    "\n",
    "#### Loss Function\n",
    "\n",
    "We need a loss function that measures how close the model's prediction is to the true target number.  It must also be lower when the model is closer.  Luckily, our regression metrics already do that!  Mean abosolute error, mean squared error, or root mean squared error would all get the job done, but in regression we are often interested in avoiding larger errors, preferring many small errors instead.  While MAE could be one option if average error is our main concern, MSE or RMSE would help train our model to especially avoid larger errors and prefer more smaller ones.  MSE and RMSE both tell much the same story, but RMSE has an extra calculation, the square root.  MSE would be the more efficient as it is less computationall expensive.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We will be importing NumPy as always, because it's so useful!  We are also going to import some classes from Keras.\n",
    "\n",
    "* **keras.models.Sequential**: This is a base model type.  Keras uses 2 types of models, Sequential and Functional.  Sequential is what we will be using in the next few lessons because it is simple to create feed forward model where data flows linearly from beginning to end.  Functional models are good for more advanced work when you start creating models where data loops, skips layers, is duplicated or when models have multiple inputs at multiple layers, such as with transformer models.\n",
    "\n",
    "* **keras.layers.Dense**: This is our basic dense layer.  For this and the next few lessons these are the layer types we will be using.  As you saw in the previous lessons, these layers can have an arbitrary number of nodes and all nodes in one layer connect to all nodes in the next layer.  They are densely connected.\n",
    "\n",
    "* **keras.layers.Input**: This is our input layer to our model.\n",
    "\n",
    "* **keras.datasets.boston_housing.load_data**: Like Scikit-Learn, Keras comes with some standard datasets for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Scikit-Learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## Keras Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.datasets.boston_housing import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comes to us already split and has 404 samples and 13 columns.  \n",
    "\n",
    "* **Samples** 404 is generally too small for deep learning.  We could probably do just as well with a traditional model.  Deep learning really shines with large datasets where the model can find subtler patterns than more traditional models.  But, we will use this one for demonstration\n",
    "\n",
    "* **Features** The data has 13 features.  This is important to note because it will determine the size of our input layer and thus the number of weights for each node in our first hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, 0.00000e+00, 5.38000e-01,\n",
       "        6.14200e+00, 9.17000e+01, 3.97690e+00, 4.00000e+00, 3.07000e+02,\n",
       "        2.10000e+01, 3.96900e+02, 1.87200e+01],\n",
       "       [2.17700e-02, 8.25000e+01, 2.03000e+00, 0.00000e+00, 4.15000e-01,\n",
       "        7.61000e+00, 1.57000e+01, 6.27000e+00, 2.00000e+00, 3.48000e+02,\n",
       "        1.47000e+01, 3.95380e+02, 3.11000e+00],\n",
       "       [4.89822e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 6.31000e-01,\n",
       "        4.97000e+00, 1.00000e+02, 1.33250e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.75520e+02, 3.26000e+00],\n",
       "       [3.96100e-02, 0.00000e+00, 5.19000e+00, 0.00000e+00, 5.15000e-01,\n",
       "        6.03700e+00, 3.45000e+01, 5.98530e+00, 5.00000e+00, 2.24000e+02,\n",
       "        2.02000e+01, 3.96900e+02, 8.01000e+00],\n",
       "       [3.69311e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 7.13000e-01,\n",
       "        6.37600e+00, 8.84000e+01, 2.56710e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.91430e+02, 1.46500e+01]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Head\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is all numeric.  Like Scikit-Learn models, Keras and TensorFlow require all features to be numeric.  In addition, while Scikit-Learn models can handle string labels in classification tasks, Keras and TensorFlow require all targets and labels to be numeric as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## Null Values\n",
    "for data in [X_train, y_train, X_test, y_test]:\n",
    "    print(np.isnan(data).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has no null values.  This is very important to check.  Unlike Scikit-Learn, TensorFlow based models will not throw errors if you have NaNs in your data, however, the model will not converge.  This can be a difficult problem to debug because it is essentially a silent error.  Make sure you check and correct any missing values in your data before modeling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Keras and TensorFlow models require all data to be numeric and free from missing values.  If either of these assumptions were violated, now would be the time to apply appropriate processing to fix them.  Scikit-Learn preprocessors work fine here.\n",
    "\n",
    "### Scaling\n",
    "While not necessarily required, research has suggested that scaling input variables improves the rate at which deep learning models converge on optimal solutions by preventing early layer weights from growing too large (exploding gradients) or too small (vanishing gradients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "Keras is a fully **object-oriented** library.  This means nearly everything will be a class: models, layers, metrics, etc.  We will be instantiating and combining many objects here.\n",
    "\n",
    "For this demonstration, we will create the same model architecture we used in the previous lesson: One hidden layer with 2 nodes and an output layer.  The number of nodes and layers are hyperparameters for you to tune as you develop your models.\n",
    "\n",
    "To create and get our model ready for training, we will take the following steps:\n",
    "\n",
    "1. **Determine input size**:  We will use `X_train_sc.shape[1]` to retrieve an integer value of the number of input features.  We will add an Input layer with this shape as the first layer.\n",
    "\n",
    "When determining the shape of your input layer, be sure you are using your processed data.  If you have changed the number of features, or example with one-hot encoding, Keras will need to know the final number of features AFTER processing.\n",
    "\n",
    "2. **Instantiate a base model**:  We will use `Sequential()` for this.\n",
    "3. **Add layers**:  There are two ways we can do this.  We can pass `Sequential()` a list of layer objects, or we can use the `Sequential.add()` method to add layers.  In either case, the layers will be ordered, either in the order of the list we pass, or in the order in which we add them.  We will be using `Dense()` layers.  We will need to specify the number of nodes in each layer as we instantiate them.  In this case we will create an input layer, one hidden layer with 10 nodes, and an output layer with 1 node, since we want our model to make predictions of 1 number per sample.\n",
    "4. **Activation Functions**: These can be added as layers or specified as a keyword in other layer objects.  Applying them as separate layers allows a user to customize activation functions, or use functions that are not accessible through standard keywords in other layer objects.  We will use keywords in our `Dense()` layers for our activation functions with `activation=`.  In this case we will continue to use a sigmoid activation function for our hidden layer, like we did in the previous lesson, but we will not include an activation function for our output layer.  This is because we do not want to limit the range of values our model can predict.  Non-linearity in the model will be handled by the hidden layer activation function.\n",
    "5. **Compile the model**: Once the model architecture is constructed, the model must be compiled with a loss function and optionally a gradient descent optimizer and additional metrics to track during training.  We will be using an 'mse' loss function.  Again, this can either be passed as a class object, or as a keyword.  This allows you to create custom loss functions if you want.\n",
    "\n",
    "**Optimizers** Optimizers are variations on the gradient descent algorithm that can help models to more quickly converge on the global minimum of the loss landscape.  There are several to choose from and they will affect the rate at which a model converges on a solution.  In this demonstration we will use the default, **Stochastic Gradient Descent**.  It has many arguments we can pass to customize it, but by default it just applies a learning rate of .001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine size of input layer\n",
    "input_dim = (X_train_sc.shape[1],) #tuple of shape in input, not counting batch size.  In this case we are passing a 1 dimensional tensor of size X_train.shape[1]\n",
    "\n",
    "## Instantiate Model\n",
    "\n",
    "model = Sequential(name='first_model')\n",
    "## Add layers\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Input(shape=input_dim, name='input_layer'))\n",
    "model.add(Dense(units=10, # 0 nodes\n",
    "                activation='sigmoid', # add a sigmoid activation function\n",
    "                name='first_hidden_layer'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, # Keras will automatically determine the number of weights (2) based on the shape of the previous layer, \n",
    "                name='output_layer')) # and we don't need an activation function\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(loss='mse', # mean squared error loss function\n",
    "              metrics=['mae']) # also track the mean absolute error at each epoch of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"first_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"first_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ first_hidden_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ first_hidden_layer (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │        \u001b[38;5;34m140\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │         \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">151</span> (604.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m151\u001b[0m (604.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">151</span> (604.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m151\u001b[0m (604.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Examine the model architecture.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that our model has one layer with 28 parameters, 13 features * 2 nodes + 2 biases.  Since there are 2 nodes, it outputs 2 values.  The output layer has one node with 2 weights + 1 bias and outputs 1 value.  The output of the output layer will the model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "In this step we will fit the model on the training data.  We will also need to specify a number of training epochs, as the model does not have a way of knowing when it is \"done\" training.  In future lessons we will talk about some ways we can automate the choice of training epochs, for but now we will choose a number.\n",
    "\n",
    "`model.fit()` returns a dictionary recording the model metrics at each training step.  It will store the loss by default, so MSE, but it will also store the metric we specified when we compiled it, MAE.  We will save the data to visualize after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 527.0168 - mae: 21.1778  \n",
      "Epoch 2/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 505.3374 - mae: 20.8261\n",
      "Epoch 3/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 541.7723 - mae: 21.4525\n",
      "Epoch 4/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 519.4960 - mae: 20.9575\n",
      "Epoch 5/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 523.8756 - mae: 20.8493 \n",
      "Epoch 6/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 549.2515 - mae: 21.4489 \n",
      "Epoch 7/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 503.2938 - mae: 20.5510 \n",
      "Epoch 8/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 500.6531 - mae: 20.4089\n",
      "Epoch 9/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 499.9682 - mae: 20.3150\n",
      "Epoch 10/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 498.7412 - mae: 20.4378\n",
      "Epoch 11/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 500.6472 - mae: 20.3850\n",
      "Epoch 12/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 496.6793 - mae: 20.1507\n",
      "Epoch 13/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 491.8843 - mae: 19.8852 \n",
      "Epoch 14/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 460.0553 - mae: 19.2556\n",
      "Epoch 15/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 442.0065 - mae: 18.9860\n",
      "Epoch 16/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 460.6723 - mae: 19.4085\n",
      "Epoch 17/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 463.3157 - mae: 19.3410\n",
      "Epoch 18/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 449.9565 - mae: 19.1284\n",
      "Epoch 19/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 425.2352 - mae: 18.4765\n",
      "Epoch 20/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 433.8070 - mae: 18.6708\n",
      "Epoch 21/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 432.1099 - mae: 18.5641\n",
      "Epoch 22/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 408.3410 - mae: 18.1323 \n",
      "Epoch 23/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 406.6949 - mae: 18.0285\n",
      "Epoch 24/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 408.9888 - mae: 18.0454\n",
      "Epoch 25/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 406.3268 - mae: 17.9144\n",
      "Epoch 26/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 392.9642 - mae: 17.5073\n",
      "Epoch 27/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 387.7746 - mae: 17.2891\n",
      "Epoch 28/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 383.7766 - mae: 17.3865\n",
      "Epoch 29/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 371.1335 - mae: 16.9731 \n",
      "Epoch 30/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 392.1269 - mae: 17.2399\n",
      "Epoch 31/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 350.4759 - mae: 16.4253\n",
      "Epoch 32/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 376.0438 - mae: 17.0022\n",
      "Epoch 33/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 362.1542 - mae: 16.5220\n",
      "Epoch 34/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 392.7381 - mae: 17.3076\n",
      "Epoch 35/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 368.7820 - mae: 16.6141\n",
      "Epoch 36/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - loss: 338.9891 - mae: 15.9204\n",
      "Epoch 37/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 363.1329 - mae: 16.3352  \n",
      "Epoch 38/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 347.9818 - mae: 16.0154 \n",
      "Epoch 39/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 337.6047 - mae: 15.7869  \n",
      "Epoch 40/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 336.6121 - mae: 15.7156 \n",
      "Epoch 41/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 327.2480 - mae: 15.4002 \n",
      "Epoch 42/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 334.1010 - mae: 15.6424 \n",
      "Epoch 43/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 313.5399 - mae: 15.0492 \n",
      "Epoch 44/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 320.4585 - mae: 15.1913 \n",
      "Epoch 45/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167us/step - loss: 320.9397 - mae: 14.9032\n",
      "Epoch 46/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 290.4451 - mae: 14.4912  \n",
      "Epoch 47/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 291.5438 - mae: 14.0859 \n",
      "Epoch 48/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 309.1714 - mae: 14.6663 \n",
      "Epoch 49/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 274.7130 - mae: 13.9337  \n",
      "Epoch 50/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 266.6613 - mae: 13.7415 \n",
      "Epoch 51/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 305.7155 - mae: 14.3517 \n",
      "Epoch 52/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step - loss: 253.1918 - mae: 13.3896\n",
      "Epoch 53/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 265.4118 - mae: 13.7279  \n",
      "Epoch 54/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 272.7321 - mae: 13.9077 \n",
      "Epoch 55/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 265.5509 - mae: 13.6761 \n",
      "Epoch 56/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 262.1303 - mae: 13.3657 \n",
      "Epoch 57/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 254.6799 - mae: 13.3195 \n",
      "Epoch 58/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 282.4423 - mae: 13.8342  \n",
      "Epoch 59/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 278.5605 - mae: 13.5613 \n",
      "Epoch 60/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 250.6334 - mae: 13.0825 \n",
      "Epoch 61/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 238.9476 - mae: 12.6000 \n",
      "Epoch 62/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 238.8037 - mae: 12.5692 \n",
      "Epoch 63/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 225.0344 - mae: 12.2999 \n",
      "Epoch 64/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 233.2923 - mae: 12.2616  \n",
      "Epoch 65/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 226.9248 - mae: 12.2558  \n",
      "Epoch 66/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 196.2162 - mae: 11.3819\n",
      "Epoch 67/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 197.3799 - mae: 11.2845 \n",
      "Epoch 68/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.3143 - mae: 11.6761 \n",
      "Epoch 69/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 244.0885 - mae: 12.2921 \n",
      "Epoch 70/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 236.5250 - mae: 12.0624  \n",
      "Epoch 71/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 202.7204 - mae: 11.4097 \n",
      "Epoch 72/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 205.1604 - mae: 11.2342 \n",
      "Epoch 73/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 179.8391 - mae: 10.5695\n",
      "Epoch 74/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 187.1514 - mae: 10.6651  \n",
      "Epoch 75/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 187.9031 - mae: 10.7038\n",
      "Epoch 76/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 207.5468 - mae: 11.2577 \n",
      "Epoch 77/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 206.9190 - mae: 11.0460  \n",
      "Epoch 78/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 199.3796 - mae: 10.8157 \n",
      "Epoch 79/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 181.9996 - mae: 10.3723 \n",
      "Epoch 80/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 193.0413 - mae: 10.7081 \n",
      "Epoch 81/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 202.2830 - mae: 10.6987 \n",
      "Epoch 82/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 188.1301 - mae: 10.4549 \n",
      "Epoch 83/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 170.0809 - mae: 9.8483\n",
      "Epoch 84/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 167.0087 - mae: 9.5871   \n",
      "Epoch 85/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 163.3601 - mae: 9.4285 \n",
      "Epoch 86/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 155.6408 - mae: 9.3705 \n",
      "Epoch 87/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 142.0200 - mae: 9.0265\n",
      "Epoch 88/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - loss: 148.2378 - mae: 9.1429\n",
      "Epoch 89/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 168.3538 - mae: 9.6479 \n",
      "Epoch 90/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 150.4635 - mae: 8.9485\n",
      "Epoch 91/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 150.1683 - mae: 9.2228\n",
      "Epoch 92/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 150.2357 - mae: 9.0173\n",
      "Epoch 93/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 133.8659 - mae: 8.5774  \n",
      "Epoch 94/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 149.3635 - mae: 8.9013  \n",
      "Epoch 95/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 135.7112 - mae: 8.6061 \n",
      "Epoch 96/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 151.6502 - mae: 8.9188   \n",
      "Epoch 97/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 140.8156 - mae: 8.7995\n",
      "Epoch 98/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 133.8471 - mae: 8.5106 \n",
      "Epoch 99/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 133.4899 - mae: 8.1671\n",
      "Epoch 100/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 134.1098 - mae: 8.3158 \n",
      "Epoch 101/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 119.6169 - mae: 7.8990\n",
      "Epoch 102/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step - loss: 126.1235 - mae: 8.2372\n",
      "Epoch 103/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 130.7209 - mae: 8.1882 \n",
      "Epoch 104/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 119.8340 - mae: 7.6939\n",
      "Epoch 105/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 128.5103 - mae: 8.3024 \n",
      "Epoch 106/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 140.0905 - mae: 8.3157 \n",
      "Epoch 107/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 114.7036 - mae: 7.6916 \n",
      "Epoch 108/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 111.9466 - mae: 7.6343\n",
      "Epoch 109/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 115.1818 - mae: 7.5492 \n",
      "Epoch 110/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 122.9232 - mae: 7.8809  \n",
      "Epoch 111/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.0650 - mae: 7.1188\n",
      "Epoch 112/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step - loss: 113.6475 - mae: 7.3159\n",
      "Epoch 113/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 105.4908 - mae: 7.0932\n",
      "Epoch 114/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 95.9472 - mae: 6.8675 \n",
      "Epoch 115/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 109.5945 - mae: 7.3467\n",
      "Epoch 116/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - loss: 103.8433 - mae: 7.2517\n",
      "Epoch 117/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108.2717 - mae: 7.1464\n",
      "Epoch 118/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 98.5816 - mae: 6.8756\n",
      "Epoch 119/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 93.5044 - mae: 6.6057\n",
      "Epoch 120/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 95.2025 - mae: 6.7534\n",
      "Epoch 121/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 85.4014 - mae: 6.3984\n",
      "Epoch 122/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 96.7038 - mae: 6.6648\n",
      "Epoch 123/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 95.3369 - mae: 6.7062\n",
      "Epoch 124/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 95.4809 - mae: 6.8296\n",
      "Epoch 125/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 105.1964 - mae: 7.0289\n",
      "Epoch 126/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 97.6883 - mae: 6.9456  \n",
      "Epoch 127/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.9932 - mae: 6.7239 \n",
      "Epoch 128/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 81.9662 - mae: 6.3127  \n",
      "Epoch 129/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77.6708 - mae: 5.9251 \n",
      "Epoch 130/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 81.8184 - mae: 6.2919\n",
      "Epoch 131/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 92.6981 - mae: 6.5002\n",
      "Epoch 132/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 95.5608 - mae: 6.6750\n",
      "Epoch 133/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 94.5249 - mae: 6.6004\n",
      "Epoch 134/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 88.4404 - mae: 6.4996\n",
      "Epoch 135/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 103.5952 - mae: 7.1660\n",
      "Epoch 136/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96.5554 - mae: 6.8117 \n",
      "Epoch 137/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79.6727 - mae: 6.2614 \n",
      "Epoch 138/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94.2771 - mae: 6.6722 \n",
      "Epoch 139/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.5451 - mae: 6.4750 \n",
      "Epoch 140/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77.1967 - mae: 6.1376  \n",
      "Epoch 141/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82.5649 - mae: 6.1968 \n",
      "Epoch 142/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.2214 - mae: 6.6985 \n",
      "Epoch 143/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 71.2141 - mae: 6.0891  \n",
      "Epoch 144/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80.6952 - mae: 6.3037  \n",
      "Epoch 145/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75.5153 - mae: 6.1473 \n",
      "Epoch 146/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.3192 - mae: 6.7848 \n",
      "Epoch 147/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 77.3468 - mae: 6.1866  \n",
      "Epoch 148/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.7440 - mae: 6.7584  \n",
      "Epoch 149/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.1308 - mae: 6.7083 \n",
      "Epoch 150/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 71.6217 - mae: 6.0172  \n",
      "Epoch 151/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 90.2818 - mae: 6.8816  \n",
      "Epoch 152/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79.9824 - mae: 6.4784 \n",
      "Epoch 153/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80.8514 - mae: 6.3172 \n",
      "Epoch 154/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83.0583 - mae: 6.5703 \n",
      "Epoch 155/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 96.4558 - mae: 6.9889\n",
      "Epoch 156/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82.1072 - mae: 6.5180 \n",
      "Epoch 157/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step - loss: 86.6093 - mae: 6.7048\n",
      "Epoch 158/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 86.4312 - mae: 6.7883  \n",
      "Epoch 159/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84.1614 - mae: 6.6239 \n",
      "Epoch 160/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 89.2435 - mae: 6.7575 \n",
      "Epoch 161/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 79.4485 - mae: 6.3273  \n",
      "Epoch 162/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 84.1126 - mae: 6.6628\n",
      "Epoch 163/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.3394 - mae: 6.8356  \n",
      "Epoch 164/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 88.7020 - mae: 6.8284\n",
      "Epoch 165/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 74.9155 - mae: 6.2440\n",
      "Epoch 166/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 88.5232 - mae: 6.8467\n",
      "Epoch 167/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83.0959 - mae: 6.6769 \n",
      "Epoch 168/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80.5696 - mae: 6.4256 \n",
      "Epoch 169/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 83.9778 - mae: 6.5803\n",
      "Epoch 170/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 83.7201 - mae: 6.6872\n",
      "Epoch 171/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 85.0245 - mae: 6.7653 \n",
      "Epoch 172/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 79.8689 - mae: 6.5527\n",
      "Epoch 173/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 79.4552 - mae: 6.5930\n",
      "Epoch 174/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 77.0538 - mae: 6.4172\n",
      "Epoch 175/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 75.1773 - mae: 6.1783\n",
      "Epoch 176/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73.1810 - mae: 6.0747 \n",
      "Epoch 177/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86.8603 - mae: 6.7879  \n",
      "Epoch 178/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 86.1717 - mae: 6.7500   \n",
      "Epoch 179/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 79.9474 - mae: 6.3671  \n",
      "Epoch 180/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83.3038 - mae: 6.5745 \n",
      "Epoch 181/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.3295 - mae: 6.8586 \n",
      "Epoch 182/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 95.7943 - mae: 7.1444  \n",
      "Epoch 183/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 85.5398 - mae: 6.5710  \n",
      "Epoch 184/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82.7826 - mae: 6.5034 \n",
      "Epoch 185/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 71.0746 - mae: 6.2593 \n",
      "Epoch 186/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80.3996 - mae: 6.4020 \n",
      "Epoch 187/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 89.8527 - mae: 6.8550   \n",
      "Epoch 188/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83.7403 - mae: 6.6881 \n",
      "Epoch 189/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.6145 - mae: 6.8176  \n",
      "Epoch 190/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83.8707 - mae: 6.4860 \n",
      "Epoch 191/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 92.2489 - mae: 7.0348   \n",
      "Epoch 192/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80.1560 - mae: 6.5747 \n",
      "Epoch 193/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82.5098 - mae: 6.5849 \n",
      "Epoch 194/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86.4127 - mae: 6.6710  \n",
      "Epoch 195/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 70.8163 - mae: 6.0311  \n",
      "Epoch 196/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 80.1909 - mae: 6.5754  \n",
      "Epoch 197/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 97.4393 - mae: 7.1476  \n",
      "Epoch 198/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76.0921 - mae: 6.4011 \n",
      "Epoch 199/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 90.4336 - mae: 6.8490\n",
      "Epoch 200/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84.9803 - mae: 6.7304 \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_sc, y_train,\n",
    "                    epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAJOCAYAAACTP/9cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACExklEQVR4nOzdd1QUZ9sG8GsWlgWWpZdlpYgKNhSxi10j9hJNNFZMTNRETYgay5uiKa9G872aYmKaLSaxJJaYGGsE1KixAIoNMaKAgCjSy7Kw8/1hsskKCkqZBa7fOXOO+8wzs/cOKxfTnhFEURRBREREJkcmdQFERERUNoY0ERGRiWJIExERmSiGNBERkYliSBMREZkohjQREZGJYkgTERGZKIY0ERGRiWJIExERmSiGNJFEBEGo0BQeHl6p91m8eDEEQXisZcPDw6ukhtr23kSmwlzqAojqq+PHjxu9fvfddxEWFoZDhw4Ztbdo0aJS7/P8889jwIABj7Vs27Ztcfz48UrXQESPhyFNJJHOnTsbvXZxcYFMJivVfr/8/HxYW1tX+H08PDzg4eHxWDXa2tqWWw8RVR8e7iYyYb169YK/vz8OHz6MoKAgWFtb47nnngMAbNmyBcHBwXB3d4eVlRWaN2+OBQsWIC8vz2gdZR3ubtiwIYYMGYK9e/eibdu2sLKyQrNmzbB27VqjfmUdcp48eTJsbGxw9epVDBo0CDY2NvD09MScOXOg1WqNlk9KSsJTTz0FlUoFe3t7jB8/HqdOnYIgCFi/fv1jbZNdu3ahS5cusLa2hkqlQr9+/Uodlbh9+zamTp0KT09PKBQKuLi4oGvXrjh48KChT1RUFIYMGQJXV1coFApoNBoMHjwYSUlJj1UXUXXgnjSRiUtJScGECRMwb948LFmyBDLZvb+t4+LiMGjQIISGhkKpVOLy5ctYtmwZTp48WeqQeVnOnj2LOXPmYMGCBXBzc8PXX3+NKVOmoEmTJujRo8dDl9XpdBg2bBimTJmCOXPm4PDhw3j33XdhZ2eHt956CwCQl5eH3r174+7du1i2bBmaNGmCvXv3YsyYMY+9Lb7//nuMHz8ewcHB2LRpE7RaLZYvX45evXrht99+Q7du3QAAEydORGRkJP773//Cz88PmZmZiIyMRHp6uqG2fv36wcfHB59++inc3NyQmpqKsLAw5OTkPHZ9RFVOJCKTEBISIiqVSqO2nj17igDE33777aHL6vV6UafTiRERESIA8ezZs4Z5ixYtEu//r+7t7S1aWlqKN27cMLQVFBSIjo6O4rRp0wxtYWFhIgAxLCzMqE4A4tatW43WOWjQILFp06aG159++qkIQNyzZ49Rv2nTpokAxHXr1j30M93/3iUlJaJGoxFbtWollpSUGPrl5OSIrq6uYlBQkKHNxsZGDA0NfeC6T58+LQIQd+7c+dAaiKTGw91EJs7BwQF9+vQp1X7t2jWMGzcOarUaZmZmkMvl6NmzJwDg0qVL5a63TZs28PLyMry2tLSEn58fbty4Ue6ygiBg6NChRm2tW7c2WjYiIgIqlarURWtjx44td/1liY2NRXJyMiZOnGg4mgAANjY2GDVqFE6cOIH8/HwAQMeOHbF+/Xq89957OHHiBHQ6ndG6mjRpAgcHB8yfPx+ff/45Ll68+Fg1EVU3hjSRiXN3dy/Vlpubi+7du+OPP/7Ae++9h/DwcJw6dQrbt28HABQUFJS7Xicnp1JtCoWiQstaW1vD0tKy1LKFhYWG1+np6XBzcyu1bFltFfH3oeqytodGo4Fer0dGRgaAe+frQ0JC8PXXX6NLly5wdHTEpEmTkJqaCgCws7NDREQE2rRpg//85z9o2bIlNBoNFi1aVCrQiaTEc9JEJq6se5wPHTqE5ORkhIeHG/aeASAzM7MGK3s4JycnnDx5slT730H5OOsD7p2jv19ycjJkMhkcHBwAAM7Ozvjwww/x4YcfIiEhAbt27cKCBQuQlpaGvXv3AgBatWqFzZs3QxRFnDt3DuvXr8c777wDKysrLFiw4LFqJKpq3JMmqoX+Dm6FQmHU/sUXX0hRTpl69uyJnJwc7Nmzx6h98+bNj7W+pk2bokGDBvj+++8hiqKhPS8vD9u2bTNc8X0/Ly8vzJw5E/369UNkZGSp+YIgICAgACtXroS9vX2ZfYikwj1polooKCgIDg4OmD59OhYtWgS5XI7vvvsOZ8+elbo0g5CQEKxcuRITJkzAe++9hyZNmmDPnj3Yt28fABidV64ImUyG5cuXY/z48RgyZAimTZsGrVaLDz74AJmZmXj//fcBAFlZWejduzfGjRuHZs2aQaVS4dSpU9i7dy9GjhwJAPjll1/w2WefYcSIEWjUqBFEUcT27duRmZmJfv36Ve2GIKoEhjRRLeTk5ITdu3djzpw5mDBhApRKJYYPH44tW7agbdu2UpcHAFAqlTh06BBCQ0Mxb948CIKA4OBgfPbZZxg0aBDs7e0feZ3jxo2DUqnE0qVLMWbMGJiZmaFz584ICwtDUFAQgHsXwHXq1AkbN27E9evXodPp4OXlhfnz52PevHkAAF9fX9jb22P58uVITk6GhYUFmjZtivXr1yMkJKQqNwNRpQjiv48bERFVsyVLluCNN95AQkLCY4+ERlRfcE+aiKrNqlWrAADNmjWDTqfDoUOH8PHHH2PChAkMaKIKYEgTUbWxtrbGypUrcf36dWi1WsNh5zfeeEPq0ohqBR7uJiIiMlG8BYuIiMhEMaSJiIhMFEOaiIjIRPHCsTLo9XokJydDpVKVOSQjERFRZYiiiJycHGg0mocO7MOQLkNycjI8PT2lLoOIiOq4xMTEh96OyJAug0qlAnBv49na2kpcDRER1TXZ2dnw9PQ05M2DMKTL8PchbltbW4Y0ERFVm/JOqfLCMSIiIhPFkCYiIjJRDGkiIiITxZAmIiIyUQxpIiIiE8WQrma3c7RSl0BERLUUb8GqRjmFOnRachDudlbo1MgRL/VqjCauD78njoiI6G/ck65Gsak5EAQBNzMLsD3yJiauOYmiYr3UZRERUS3BkK5G7Rs64uyiYGx4riOcbRRIySrE7phkqcsiIqJagiFdzWwU5ujp54LJQd4AgK8Ox0MURYmrIiKi2oAhXUPGd/KGpVyGiynZOP5nutTlEBFRLcCQriEOSgs83e7ek7W+OnJN4mqIiKg2YEjXoCndfCAIQFjsbVxNy5G6HCIiMnEM6RrU0FmJfs3dAABfH4mXuBoiIjJ1DOka9kKPRgCA7VE3OdAJERE9FEO6hrX3dkCApz2KivV4Y2cMtMUlUpdEREQmiiFdwwRBwPz+TSE3E7Dvwi08u+4Ucgp1UpdFREQmiCEtgaAmzlg3uSOUFmY49mc6xn51goe+iYioFIa0RLr5OmPz1C5wUlrg/M1sPP35MQY1EREZYUhLqJWHHX58MQiejla4np6P/+yI4WhkRERkwJCWmI+zEl9Nag+5mYADF29hR9RNqUsiIiITwZA2Ac3Utgh9wg8AsHjXBdzJ5WFvIiIysZBevHgxBEEwmtRqtWG+KIpYvHgxNBoNrKys0KtXL1y4cMFoHVqtFrNmzYKzszOUSiWGDRuGpKSkmv4oj2xaj0ZoqbFFdmExvjzMYUOJiMjEQhoAWrZsiZSUFMMUExNjmLd8+XKsWLECq1atwqlTp6BWq9GvXz/k5PwzxGZoaCh27NiBzZs34+jRo8jNzcWQIUNQUmLa9yObm8kwt39TAMA3x68jLadQ4oqIiEhqJhfS5ubmUKvVhsnFxQXAvb3oDz/8EK+//jpGjhwJf39/bNiwAfn5+fj+++8BAFlZWVizZg3+97//4YknnkBgYCC+/fZbxMTE4ODBg1J+rArp5eeCQC97FOr0+Dyce9NERPWdyYV0XFwcNBoNfHx88Mwzz+DatXthFR8fj9TUVAQHBxv6KhQK9OzZE8eOHQMAnDlzBjqdzqiPRqOBv7+/oU9ZtFotsrOzjSYpCIKA2f3unZv+9o8bvCWLiKieM6mQ7tSpE7755hvs27cPX331FVJTUxEUFIT09HSkpqYCANzc3IyWcXNzM8xLTU2FhYUFHBwcHtinLEuXLoWdnZ1h8vT0rOJPVnHdmjgj0OvesKEbjl2XrA4iIpKeSYX0wIEDMWrUKLRq1QpPPPEEdu/eDQDYsGGDoY8gCEbLiKJYqu1+5fVZuHAhsrKyDFNiYmIlPkXlCIKAaT0aA7h3bjpPWyxZLUREJC2TCun7KZVKtGrVCnFxcYarvO/fI05LSzPsXavVahQVFSEjI+OBfcqiUChga2trNEmpXws3NHJWIruwGB/si8Xucym8LYuIqB4y6ZDWarW4dOkS3N3d4ePjA7VajQMHDhjmFxUVISIiAkFBQQCAdu3aQS6XG/VJSUnB+fPnDX1qAzOZYHik5fpj1zHj+0g8t/4URyMjIqpnzKUu4N/mzp2LoUOHwsvLC2lpaXjvvfeQnZ2NkJAQCIKA0NBQLFmyBL6+vvD19cWSJUtgbW2NcePGAQDs7OwwZcoUzJkzB05OTnB0dMTcuXMNh89rk5FtG+D4n+lIzMjHxeRsnEvKwuG4O+jp5yJ1aUREVENMKqSTkpIwduxY3LlzBy4uLujcuTNOnDgBb29vAMC8efNQUFCAl156CRkZGejUqRP2798PlUplWMfKlSthbm6O0aNHo6CgAH379sX69ethZmYm1cd6LApzM3w8NhAA8O4vF7HmaDw+C7vKkCYiqkcEkcdQS8nOzoadnR2ysrIkPz8NAClZBeixPAy6EhEfjmmDHn4ucFRaSF0WERE9pormjEmfk6Z73O2s8GRgAwBA6JZodPzvQWw9Ld0V6EREVDMY0rXEnOCmGOivhoeDFYr1Ihb9dAGJd/OlLouIiKoRQ7qWcLO1xOoJ7XD4td7o5OOIAl0JFmw/xyu+iYjqMIZ0LSOTCVg2qjUs5TL8fjUdP0UnS10SERFVE4Z0LdTQWYlZfXwBAB8evILiEr3EFRERUXVgSNdSk4Mawklpgevp+dgRdVPqcoiIqBowpGsppcIc03veG+P740Nx0HFvmoiozmFI12ITOnvD2UaBxLsF+OoInz9NRFTXMKRrMSsLMywY2AwA8OHBOPx5O1fiioiIqCoxpGu5UW0boKefC4qK9Zj/4zmU6HlLFhFRXcGQruUEQcCSka2gtDDD6RsZ+DziT6lLIiKiKsKQrgMa2Fth8bCWAIAVB67gzI2McpYgIqLagCFdRzzVzgPDAjQo0YsI3RIFbXGJ1CUREVElMaTrCEEQ8N8n/eGqune1907eO01EVOsxpOsQlaUcL3RvBAD4POIaLyIjIqrlGNJ1zLhOXrCzkiP+Th72nE+RuhwiIqoEhnQdo1SYY3JQQwDAWz9dwNdHrqFQx/PTRES1EUO6Dnq2a0M0cbXB3bwivLf7EiatPcmHcBAR1UIM6TrI3toCv77cHctGtYKNwhwn4+/iw4NxUpdFRESPiCFdR1mYyzCmgxeWjGwFAPg0/Cp+v3pH4qqIiOhRMKTruGEBGozt6AVRBBZuj+H5aSKiWoQhXQ+8Prg5XFUKJNzNx5qj8VKXQ0REFcSQrgdsFOb4z6DmAIBVh67iZmaBxBUREVFFMKTrieFtNGjv7YACXQlGf34cF5OzpS6JiIjKwZCuJwRBwP9GB6ChkzVuZhZg1OpjOBl/V+qyiIjoIRjS9Yi3kxI/zeiGrk2cUKArwbSNp5GQni91WURE9AAM6XrGzlqOryd1QKsGdsjI12HKhlPILyqWuiwiIioDQ7oesrIww1eT2sNVpUBcWi62RfKJWUREpoghXU+p7SwxvWdjAMB3J25AFPnELCIiU8OQrsdGtfOApVyGy6k5OH0jQ+pyiIjoPgzpeszOSo7hAQ0AAN+euCFxNUREdD+TDumlS5dCEASEhoYa2kRRxOLFi6HRaGBlZYVevXrhwoULRstptVrMmjULzs7OUCqVGDZsGJKSkmq4+tphQmdvAMCvMSn48Qy3ERGRKTHZkD516hS+/PJLtG7d2qh9+fLlWLFiBVatWoVTp05BrVajX79+yMnJMfQJDQ3Fjh07sHnzZhw9ehS5ubkYMmQISko4bvX9WnnYYXBrd+hKRMz94Szm/XgWBUXcTkREpsAkQzo3Nxfjx4/HV199BQcHB0O7KIr48MMP8frrr2PkyJHw9/fHhg0bkJ+fj++//x4AkJWVhTVr1uB///sfnnjiCQQGBuLbb79FTEwMDh48KNVHMmmfPBOIOf38IBOAraeTMOLT3/Hn7VypyyIiqvdMMqRnzJiBwYMH44knnjBqj4+PR2pqKoKDgw1tCoUCPXv2xLFjxwAAZ86cgU6nM+qj0Wjg7+9v6HM/rVaL7Oxso6k+kckEzOrri2+ndIKzjQKxt3Iw7qsTyMgrkro0IqJ6zeRCevPmzYiMjMTSpUtLzUtNTQUAuLm5GbW7ubkZ5qWmpsLCwsJoD/z+PvdbunQp7OzsDJOnp2dVfJRaJ6iJM359pRsauShxK1uLBdvP8dYsIiIJmVRIJyYm4pVXXsG3334LS0vLB/YTBMHotSiKpdru97A+CxcuRFZWlmFKTEx89OLrCFeVJT5+JhByMwH7LtzChwfjoC3mOWoiIimYVEifOXMGaWlpaNeuHczNzWFubo6IiAh8/PHHMDc3N+xB379HnJaWZpinVqtRVFSEjIyMB/a5n0KhgK2trdFUn/k3sMPc4KYAgI9+i0Of/4vA2cRMaYsiIqqHTCqk+/bti5iYGERHRxum9u3bY/z48YiOjkajRo2gVqtx4MABwzJFRUWIiIhAUFAQAKBdu3aQy+VGfVJSUnD+/HlDHyrf1B6N8P7IVnCzVeBmZgHe2Hmeh76JiGqYudQF/JtKpYK/v79Rm1KphJOTk6E9NDQUS5Ysga+vL3x9fbFkyRJYW1tj3LhxAAA7OztMmTIFc+bMgZOTExwdHTF37ly0atWq1IVo9GCCIOCZjl7o18INXZcdQszNLBz/Mx1BTZylLo2IqN4wqZCuiHnz5qGgoAAvvfQSMjIy0KlTJ+zfvx8qlcrQZ+XKlTA3N8fo0aNRUFCAvn37Yv369TAzM5Ow8trJyUaB0e098c3xG/ji8DWGNBFRDRJEHsMsJTs7G3Z2dsjKyqr356cBICE9H73+Lwx6Efhhehd0aOgodUlERLVaRXPGpM5Jk2nycrLG4NYaAMDYL0/g49/iUFyil7gqIqK6jyFNFfLu8Jbo39INxXoRKw5cwdSNZ5CrLZa6LCKiOo0hTRVib22Bzye0w8oxAVCYy3DochpGf34cOYU6qUsjIqqzGNJUYYIg4MlAD2ye2hnONha4mJKN/+2/InVZRER1FkOaHlmglwNWjmkDAPjm+HXEJGVJWxARUR3FkKbH0t3XBcMCNNCLwPxt53jYm4ioGjCk6bG9MaQ57KzkuJiSjadWH0dSRr7UJRER1SkMaXpsripLfDulE1xV9x5vOeaLE8jmHjURUZVhSFOltPKww84ZXeHpaIWbmQVY+uslqUsiIqozGNJUaRp7K/zfUwEAgE0nE3H4ym2JKyIiqhsY0lQlOjVyQkgXbwDAwu0xHOiEiKgKMKSpyswb0IyHvYmIqhBDmqqMUmGOZaNaAwC++yMB/9sfi19jUjjONxHRY2JIU5UKauyMiZ3vHfb+5NBVvPRdJOb8cFbiqoiIaieGNFW51wc3x+uDmuPJwAaQCcBP0cn47dItqcsiIqp1zKUugOoeS7kZXujRCADgolLgy8PX8MbO8+jUyAk2Cn7liIgqinvSVK1efcIPXo7WSMkqxAd7L0tdDhFRrcKQpmplZWGGpSNbAQC+OXEDZ27clbgiIqLag8ceqdp1beKMp9t54IczSXjpu0iYCQJEAN893wmNXGykLo+IyGRxT5pqxOuDm8PZxgK3srVIzipESlYhnv/mNMf6JiJ6iCoL6Q0bNmD37t2G1/PmzYO9vT2CgoJw48aNqnobqqXsrS2wbnJHvNzXF19MbAd3O0tcu52H0M3REEVR6vKIiExSlYX0kiVLYGVlBQA4fvw4Vq1aheXLl8PZ2RmvvvpqVb0N1WKtPOwwu58f+rdU46tJ7WFhLsOhy2mISsyUujQiIpNUZSGdmJiIJk2aAAB27tyJp556ClOnTsXSpUtx5MiRqnobqiP8G9hhSCt3AMAPp5MkroaIyDRVWUjb2NggPT0dALB//3488cQTAABLS0sUFBRU1dtQHfJUew8AwC9nk1GoK5G4GiIi01NlId2vXz88//zzeP7553HlyhUMHjwYAHDhwgU0bNiwqt6G6pDOPk7wcLBCjrYY+y6kSl0OEZHJqbKQ/vTTT9GlSxfcvn0b27Ztg5OTEwDgzJkzGDt2bFW9DdUhMpmAUW3v7U1/deQaEu/mS1wREZFpEUReWltKdnY27OzskJWVBVtbW6nLqdOSMvLxxIoIFOr0MJcJeLWfH2b0biJ1WURE1aqiOVNle9J79+7F0aNHDa8//fRTtGnTBuPGjUNGRkZVvQ3VMR4O1vhxehC6+zqjWC/ig32x2HQyQeqyiIhMQpWF9GuvvYbs7GwAQExMDObMmYNBgwbh2rVrmD17dlW9DdVB/g3ssHFKJ4Q+4QsAeGPneSzbexm/XbrFe6iJqF6rsmFB4+Pj0aJFCwDAtm3bMGTIECxZsgSRkZEYNGhQVb0N1WGv9PXFjfR87Ii6idXhfwIAnu3aEIuGtpS4MiIiaVTZnrSFhQXy8+9d+HPw4EEEBwcDABwdHQ172EQPIwgClj/VGstHtcbItg0AABuOXceF5CwcvHgLH+y7jFxtscRVEhHVnCoL6W7dumH27Nl49913cfLkScMtWFeuXIGHh0eF1rF69Wq0bt0atra2sLW1RZcuXbBnzx7DfFEUsXjxYmg0GlhZWaFXr164cOGC0Tq0Wi1mzZoFZ2dnKJVKDBs2DElJHCyjtpCbyTC6gydWjG6DIa3doReBkLWn8Pw3p/Fp2J8I3RwNvZ6HwImofqiykF61ahXMzc3x448/YvXq1WjQ4N6e0J49ezBgwIAKrcPDwwPvv/8+Tp8+jdOnT6NPnz4YPny4IYiXL1+OFStWYNWqVTh16hTUajX69euHnJwcwzpCQ0OxY8cObN68GUePHkVubi6GDBmCkhIOllHbvD64OawtzHAnVwsAMJcJOHjpFj7YHytxZURENcPkb8FydHTEBx98gOeeew4ajQahoaGYP38+gHt7zW5ubli2bBmmTZuGrKwsuLi4YOPGjRgzZgwAIDk5GZ6envj111/Rv3//Cr0nb8EyHTujbuKLw9cwq08TFBXrEbol+l77jK5o42kvaW1ERI+rojlTpc+TLikpwc6dO3Hp0iUIgoDmzZtj+PDhMDMze6x1/fDDD8jLy0OXLl0QHx+P1NRUw7luAFAoFOjZsyeOHTuGadOm4cyZM9DpdEZ9NBoN/P39cezYsQeGtFarhVarNbzmOXTTMSKwAUYENjC8PnzlNrZH3cSqQ1fxdUh7CSsjIqp+VRbSV69exaBBg3Dz5k00bdoUoijiypUr8PT0xO7du9G4ceMKrScmJgZdunRBYWEhbGxssGPHDrRo0QLHjh0DALi5uRn1d3NzMzwKMzU1FRYWFnBwcCjVJzX1wcNOLl26FG+//fajfFySyIw+TbAj+iYOXrqFSynZaO7OIx1EVHdV2Tnpl19+GY0bN0ZiYiIiIyMRFRWFhIQE+Pj44OWXX67wepo2bYro6GicOHECL774IkJCQnDx4kXDfEEQjPqLoliq7X7l9Vm4cCGysrIMU2JiYoXrpZrV2MUGg/56etaqsKsSV0NEVL2qLKQjIiKwfPlyODo6GtqcnJzw/vvvIyIiosLrsbCwQJMmTdC+fXssXboUAQEB+Oijj6BWqwGg1B5xWlqaYe9arVajqKio1Ahn/+5TFoVCYbii/O+JTNfMv4YN3X0uBasOxXHAEyKqs6ospBUKhdFV1n/Lzc2FhYXFY69XFEVotVr4+PhArVbjwIEDhnlFRUWIiIhAUFAQAKBdu3aQy+VGfVJSUnD+/HlDH6r9mrvbYk4/PwDA/+2/gtFfHMf0jWcQFpsmcWVERFWrys5JDxkyBFOnTsWaNWvQsWNHAMAff/yB6dOnY9iwYRVax3/+8x8MHDgQnp6eyMnJwebNmxEeHo69e/dCEASEhoZiyZIl8PX1ha+vL5YsWQJra2uMGzcOAGBnZ4cpU6Zgzpw5cHJygqOjI+bOnYtWrVoZnm9NdcOsvr6wsjDDe7sv4dT1e0dO/ohPx+8L+sDaokqvhyQikkyV/Tb7+OOPERISgi5dukAulwMAdDodhg8fjg8//LBC67h16xYmTpyIlJQU2NnZoXXr1ti7dy/69esHAJg3bx4KCgrw0ksvISMjA506dcL+/fuhUqkM61i5ciXMzc0xevRoFBQUoG/fvli/fv1jXWFOpu357o3QyccJV27l4MPfriDxbgG+/yMBz3dvJHVpRERVosrvk7569SouXboEURTRokULNGlS+x47yPuka59NJxOwcHsM3GwVODyvNxTm/KOMiExXjdwnXd7TrcLDww3/XrFiRWXeiuihRrZtgI8OxiE1uxCb/kjA5K4+UpdERFRplQrpqKioCvUr7xYpospSmJthes9GWPzzRfz310to7GqDRi42SLqbj44+jvwOElGtZPLDgkqBh7trpxK9iJc3R2H3uRSYywQU//Ugjv8+6Y/xnbwlro6I6B8VzZkquwWLSGpmMgErRgegu6+zIaABYNWhq9AW8wErRFT7MKSpTlGYm+HrkPZY92wH/L6gD9xsFUjJKsS2MzelLo2I6JExpKnOUZiboXdTVzSwt8K0HvfGjP8s/Cp0JXqJKyMiejQMaarTxnb0grONAkkZBfjqyDWpyyEieiQMaarTrCzMsGBgMwDAhwfiEJuagzM3MvDn7VyJKyMiKh/HT6Q6b1TbBth9Lhlhsbcx8KPD0IuApVyGH6cHwb+BndTlERE9EPekqc4TBAFLR7aGytIcehEQBKBQp8e0jWeQnquVujwiogfifdJl4H3SddO127lIzChAC3dbjP7iOOLv5EFjZ4kB/u6Y2qMR1HaWUpdIRPUE75Mmuk8jFxv09HOBi0qBLye2g5PSAslZhVj7ezwmrf0DJXr+vUpEpoUhTfWSr5sKh+f1xucT2sLOSo4rt3KxI4r3UhORaWFIU72lVJhjgL87Xup1717qlQeuoFDHkcmIyHQwpKneCwlqCLWtJW5mFqD78jCM+PR3RCdmSl0WERFDmshSboZ5A5oCAG7naBGdmIkXvz2DrHydxJURUX3HkCYCMLKtB47M642dM7rCx1mJlKxC/GdHDIqKOZQoEUmHIU30F09Ha7TxtMeHY9rAXCZgd0wK/Bftw7ivTiDxbr7U5RFRPcSQJrpPgKc9/vukP+ys5Cgq0ePYn+kYufoYLiRnSV0aEdUzHMykDBzMhABAFEVcTcvFrE1RuJyaA5XCHJumduZQokRUaRzMhKiSBEGAr5sKW6Z1QYeGDsjRFiNk7Uk+nIOIagxDmqgcdlZyrJ3cAf4NbJGeV4SnVh/DxhM3UMznUxNRNWNIE1WAylKODc92RAt3W2Tk6/DmzvMY8dnv3KsmomrFkCaqICcbBXbN7Ip3h7eEvbUc529mY8jHR7HrbLLUpRFRHcWQJnoE5mYyTOzSEPtCe6BrEycU6EoQujkKe8+nSF0aEdVBDGmix+Bma4mNz3XC0+08oBeBWZuicDTujtRlEVEdw5AmekwymYD3R7XGoFZq6EpEvPjdGZ6jJqIqxZAmqgQzmYCVY9qgnbcDcgqL8fyG07ialiN1WURURzCkiSpJYW6Gzye0QwN7K8TfycMTKw5j9BfHOZQoEVUaQ5qoCrioFPhmSkc80dwVZjIBJ+PvYtzXJ5CSVSB1aURUi3FY0DJwWFCqjMS7+Ziw5g/cSM+Hm60CnRs5oaefC54MbABBEKQuj4hMQK0cFnTp0qXo0KEDVCoVXF1dMWLECMTGxhr1EUURixcvhkajgZWVFXr16oULFy4Y9dFqtZg1axacnZ2hVCoxbNgwJCUl1eRHoXrM09Ea3z3fCQ3srXArW4ufopMxe+tZfHgwTurSiKiWMamQjoiIwIwZM3DixAkcOHAAxcXFCA4ORl5enqHP8uXLsWLFCqxatQqnTp2CWq1Gv379kJPzz8U6oaGh2LFjBzZv3oyjR48iNzcXQ4YMQUlJiRQfi+ohDwdr7A3tjs8ntMNzXX0AAB/9Fof391xGdqFO4uqIqLYw6cPdt2/fhqurKyIiItCjRw+IogiNRoPQ0FDMnz8fwL29Zjc3NyxbtgzTpk1DVlYWXFxcsHHjRowZMwYAkJycDE9PT/z666/o379/ue/Lw91U1T4Lv4rle+8dFbJRmGNOsB+e/Su8iaj+qZWHu++XlXXv+b2Ojo4AgPj4eKSmpiI4ONjQR6FQoGfPnjh27BgA4MyZM9DpdEZ9NBoN/P39DX3up9VqkZ2dbTQRVaWXejXByjEB8HW1Qa62GG//fBE/czhRIiqHyYa0KIqYPXs2unXrBn9/fwBAamoqAMDNzc2or5ubm2FeamoqLCws4ODg8MA+91u6dCns7OwMk6enZ1V/HCI8GeiB/a/2wPPd7u1Bv/bjWZxNzJS2KCIyaSYb0jNnzsS5c+ewadOmUvPuv0JWFMVyr5p9WJ+FCxciKyvLMCUmJj5+4UQPIQgCFg5qjl5NXVCo02PcVyew/8K9Px5N+MwTEUnEJEN61qxZ2LVrF8LCwuDh4WFoV6vVAFBqjzgtLc2wd61Wq1FUVISMjIwH9rmfQqGAra2t0URUXcxkAj4eG4igxk7IKyrB1I1n4LNwN9q8c4CHwInIiEmFtCiKmDlzJrZv345Dhw7Bx8f4whofHx+o1WocOHDA0FZUVISIiAgEBQUBANq1awe5XG7UJyUlBefPnzf0IZKaraUcG57riMlBDSEIgCgCWQU6vLolGr/GpCAqIQOXUnhtBFF9Z1JXd7/00kv4/vvv8dNPP6Fp06aGdjs7O1hZWQEAli1bhqVLl2LdunXw9fXFkiVLEB4ejtjYWKhUKgDAiy++iF9++QXr16+Ho6Mj5s6di/T0dJw5cwZmZmbl1sGru6kmZeXroC0pwZLdl7Az2nhP+rPxbTGolbtElRFRdalozpjXYE3lWr16NQCgV69eRu3r1q3D5MmTAQDz5s1DQUEBXnrpJWRkZKBTp07Yv3+/IaABYOXKlTA3N8fo0aNRUFCAvn37Yv369RUKaKKaZmctByDHB08HoEBXgn0XbsHW0hzZhcWYvTUaHg5WaO1hL3WZRCQBk9qTNhXckyapiKKIQp0ecjMBz39zGuGxt+GktMDKMW3Qw89F6vKIqIrUifukieobQRBgZWEGczMZPhkbCP8GtkjPK8KktSfxf/tieQU4UT3DkCYyUSpLOX6cHoTxnbwAAKvCrmLBthiU6BnURPUFQ5rIhFnKzfDfJ1th+ajWkAnAltOJeHlTFIqK9VKXRkQ1gCFNVAuM7uCJVePaQm4mYHdMCl745jRSswp5+JuojuOFY2XghWNkqiKu3Ma0jadRqLu3J21nJccrfX3xbNeGAAC9eG+wFCIybRXNGYZ0GRjSZMpOX7+LN3aex5VbOfj79HRQYyfcSM9HVoEOG6d0RKCXw8NXQkSSYkhXAkOaaoOiYj2+PXED//31ktHFZF6O1tj9cjeoLOUSVkdED8NbsIjqOAtzGZ7r5oMtUztjUhdvfDI2EA3srZBwNx9v/XSB56uJ6gCTGnGMiB5d+4aOaN/w3jPX3e0sMfqL49gRdRONXZSY2cdX4uqIqDK4J01Uh7Rv6Ig3BrcAAPzf/isY//UJtFq0D2O/PIH8omKJqyOiR8WQJqpjnuvmg5f7NAEA/H41HTnaYhy/lo4Xv43k/dVEtQwPdxPVQa/284OzSoE7OVr4uCjxn+3nEXHlNmZ8H4mPnmkDawv+1yeqDXh1dxl4dTfVNeGxaZj6zRkUlejR3N0WalsFrt7OxTvD/dG7qavU5RHVO7y6m4gMejV1xfcvdIKT0gKXUrIRFnsbiXcL8NoPZ5GRVyR1eUT0AAxponqifUNH7JzRFRM7e+P1Qc3h52aDO7lFWPzzBdzMLECulheWEZkaHu4uAw93U30QnZiJkZ/9bhi1zEpuho/HBqJfCzdpCyOqB3i4m4geqo2nPV7p6wczmQC5mYACXQlmfB+Jw1duS10aEf2Fe9Jl4J401SeiKKJEL2LG95HYd+EWAEBjZ4mgJs54MrABOjdy4kM7iKoYx+6uBIY01Ufa4hLM/eEcdp9Lxr+GAkdDJ2tM69kYXo7WyMzXoWdTF9goeAsXUWUwpCuBIU31WZ62GFEJmfj1fAp+OZuM7ELjC8qCGjth45RO3LsmqgSGdCUwpInuyS8qxvd/JGDzqUQAQFJGPgp1erzWvylm9G4icXVEtRdDuhIY0kRl++F0Il778RzMZAK6NHKCu50lXuzVGI1cbHAnVwu9XoSrraXUZRKZvIrmDE8sEVGFPdXOA79fvYOd0ck4evUOAGDX2WR0buSEo1fvQC+KGB6gwZzgpvB0tJa4WqLaj3vSZeCeNNGD6fUijl9Lx63sQuyIuokjcXdK9bG1NMeWaV3Q3J3/f4jKwsPdlcCQJqoYURSxLfImLiZn4+n2HiguEfHGzhicTcqCs40CP07vgobOSqnLJDI5DOlKYEgTPb6sAh2e+fIELqVkw0Zhjpd6N8bgVu5ws7WEpdysVH9RFCEIvFKc6heGdCUwpIkq53aOFs9vOIWzSVmGNkEAOjR0xNAADQb5q5FdWIx5P55F4t0CrJncHi01dhJWTFSzGNKVwJAmqjy9XsRPZ2/ii4hriL+TB22x3jDPTCbAXCYY2lxUCmx/MYgXm1G9wZCuBIY0UdUSRRE3MwuwJyYVu84mI+bmvT3sLo2ckJFfhMupOXBRKTCqrQeebu+Bxi42EldMVL0Y0pXAkCaqXvF38pBwNx/dmzjjdq4Wo784jhvp+QDu7WVP6uKNoMbOuJunRUcfJ/jw4jOqYxjSlcCQJqpZBUUlOHQ5DT+eSURYrPFTuGQCMNDfHbZWcoiiiMldG6KZmv8vqXarlY+qPHz4MIYOHQqNRgNBELBz506j+aIoYvHixdBoNLCyskKvXr1w4cIFoz5arRazZs2Cs7MzlEolhg0bhqSkpBr8FET0qKwszDC4tTvWPdsRG6d0RMeGjmjtYYd23g7Qi8DumBRsOnlveNJhn/yOJb9ewts/X8CqQ3EoKCqRunyiamNSI47l5eUhICAAzz77LEaNGlVq/vLly7FixQqsX78efn5+eO+999CvXz/ExsZCpVIBAEJDQ/Hzzz9j8+bNcHJywpw5czBkyBCcOXMGZmalb/8gItPS3dcF3X1dDK/P38zCz+eSYSU3w9nETITF3saXh68Z5u85n4ovJraDhwMvOqO6x2QPdwuCgB07dmDEiBEA7u1FazQahIaGYv78+QDu7TW7ublh2bJlmDZtGrKysuDi4oKNGzdizJgxAIDk5GR4enri119/Rf/+/Sv03jzcTWSa/h48JeLKbbjYKLAz+ibu5hVBEIBGzkp093XBxC7ehgvPikv0iEvLRVM3FWR8aheZkFp5uPth4uPjkZqaiuDgYEObQqFAz549cezYMQDAmTNnoNPpjPpoNBr4+/sb+pRFq9UiOzvbaCIi0yMIAp5q54FPxgbiraEtsGtmVwR62UMUgT9v52H9sevo+78ITNt4GieupeOZL09g4EdHMHXjGWiLeVicah+TOtz9MKmpqQAANzc3o3Y3NzfcuHHD0MfCwgIODg6l+vy9fFmWLl2Kt99+u4orJqLq5uFgjR0vdcXtHC2iEjKw9XQifruchn0XbmHfhVuGfgcv3cL0jWfwfPdGyC7QYcvpRBQV6/HhM23gqvrnqV23c7Swt5ZDblZr9l+ojqs1If23+4cPrMiQguX1WbhwIWbPnm14nZ2dDU9Pz8oVSkQ1xkWlQHBLNYJbqnHlVg6W/HoJ4bG30drDDhM7e+ONnecRFnu71JXj47/6A5umdkZxiYgVB2Kx9XQSfJyVWDqyFTo3cpLo0xD9o9aEtFqtBnBvb9nd3d3QnpaWZti7VqvVKCoqQkZGhtHedFpaGoKCgh64boVCAYVCUU2VE1FN8nNTYf2zHZGUkQ93OyuYyQQ0clHi84hr+DMtF0Ulegxq5Y6fom8iLi0X7d87aLR8/J08PPPlCfRq6oJhARoUFeuRnlcEK7kZPB2t0beZK89vU42pNSHt4+MDtVqNAwcOIDAwEABQVFSEiIgILFu2DADQrl07yOVyHDhwAKNHjwYApKSk4Pz581i+fLlktRNRzfv31d7tvB3x1SRHo/ljOnhi4td/IDmrEADQxtMec4ObYs/5FHz3RwLCY28j/L49bwBo7+2AN4e0gK+bDawt7v0KLS7RIymjAGq7sh8iQvS4TCqkc3NzcfXqVcPr+Ph4REdHw9HREV5eXggNDcWSJUvg6+sLX19fLFmyBNbW1hg3bhwAwM7ODlOmTMGcOXPg5OQER0dHzJ07F61atcITTzwh1cciIhPU2MUGh+f1xp3cIthZyWFlcS9cu/k64/nujbD1dCJ+v3oHjkoLuNgokK8rQfjlNJy+kYHhn/4OALCzksNVpUByZgHyikrgqlJgRu8m8HK0hra4BE42CqgszXE3twhpOVrcztGiUFcChVwGXzcVevi6IKdQh7DYNFhbmKORsxJeTtawMJMh9lYOMvJ06NDQAeb3nSMvKtbjyq0ceDlZw9ZSbmiPTszEiWvpaOftgHZeDrVyjz8pIx9FxXo0eoyhYUVRRLFeRIlehMJcVieermZSt2CFh4ejd+/epdpDQkKwfv16iKKIt99+G1988QUyMjLQqVMnfPrpp/D39zf0LSwsxGuvvYbvv/8eBQUF6Nu3Lz777LNHOsfMW7CIqCw3Mwvwzs8XcDTuDvLuG0RFJgD6R/xt6qpSILNAh6J/PXxEJgBKhTlyCosBAE1cbTA5qCGs5Ga4mVmAs4mZ+CP+LnK1xXBUWuD/nm4NK7k5vjl+HXvO/3OBrIeDFV7p64vBrd0RnZCJqMRMXErJhsrSHO28HRGbmo0T1+6iiasNuvs64/qdPFxOzUGBrgSCIMDb0RoW5jJcTctFZn4RAMDbSYnezVwgQMD19DzcSM/HnVwtmqlVaN/QEc3UKtgozBF7KwdH4+7gt0tpMDcTMKiVO5qpVdCL94I0p7AYYbFpuJiSjXZeDujh5wJtsR5hl9Pw6/kUAMBzXX0wrpMXbudoYWEug7NSgaISPfK0xXCwtkCuthgbjl3H6Rt3YWMph14vIv5OHnK1xX/Vao3JQQ1xOSUHv5xLhreTEk8GNkCXxk7wc1PBwvyfP3wKdSU4cPEWziZm4sbdfDRyUeKF7o3gbHPvNKi2uAQxSVkwkwlQKszhZmsJO6t//jh6HBwWtBIY0kRUnpxCHVKzCpGaXQgnpQKNXJT44XQitp5OgggRFmYy3MktQk6hDk42CriqFHBRKWBtYYY8bQmOxN1GRr4OAND0r9C4djvXEP6WchnkZjJDWN9PbiZAV2L861sQ7j205FxSliGsBAHgb3ljMgGwtZLD1lIOOys5bqTnIfu+7WxtYYagxs6wtTTHodg0ZP71swKAt4a0wHPdfCpVQ0VzxqQOdxMR1RYqSzlUlnL4uqkMbRO7NMTELg0rtHyhrgTHr6XDxUaBlhpbCIIAURRxO0eL27laNHG1gbZYjzVH4hGZkAFBEOCktDAMl+rnpsLSXy9hw/EbsLU0R/+Wakzp7oNmalsU6krwzfHrWHXoKrILi+GqUqCjjyNaauxwN0+LyIRMNLC3Qq+mLriQnI3TNzLQ2FmJ1h52sLOWo6hYj+vp9w47N3G1gYuNAnpRRHRiJn7/Mx1Wchm8HZXwdraGg7UFziVlIToxE9du50JbrIeXozVaedghuIUbCnUl2HM+FRl5RRAEATIBMJfJ0NbbAW087XH06m2cv3lvD9/L0RoTu3gjJasQ7/x8ESlZBXC3s0JRsR53crVQmMugVJgjI78IuhIRwS3c8FQ7D8Meuo+zEq4qS+hFEbvOJmNbZBLUtpaYHNQQf97Jw77zqTiXlInswmJk5uuMgreBvRX6tXCDp6M1foq+iXNJWTh46Z/b+JyUFrCyMEN+UQlsK7kX/Si4J10G7kkTUW2RnFkAZxuF0eHbv+Vpi3E3rwgeDlY1cn62RC+iqFhvOL9fWQ+6fVYU7513vv9cfUXXeTtHi6wCHbILdcguKIZSYY723v+cwxdFEX/E30XcrRzczi1CoJc9evi6wKwKz/HzcHclMKSJiKg61blhQYmIiOobhjQREZGJYkgTERGZKIY0ERGRiWJIExERmSiGNBERkYniYCZl+PuutOzsbIkrISKiuujvfCnvLmiGdBlycnIAgM+UJiKiapWTkwM7O7sHzudgJmXQ6/VITk6GSqWq9Cg92dnZ8PT0RGJiYq0bGKW21l5b6wZYu1RYe82rrXUDVVO7KIrIycmBRqOBTPbgM8/cky6DTCaDh4dHla7T1ta21n0R/1Zba6+tdQOsXSqsvebV1rqBytf+sD3ov/HCMSIiIhPFkCYiIjJRDOlqplAosGjRIigUCqlLeWS1tfbaWjfA2qXC2mteba0bqNnaeeEYERGRieKeNBERkYliSBMREZkohjQREZGJYkgTERGZKIZ0Nfrss8/g4+MDS0tLtGvXDkeOHJG6pFKWLl2KDh06QKVSwdXVFSNGjEBsbKxRn8mTJ0MQBKOpc+fOElX8j8WLF5eqS61WG+aLoojFixdDo9HAysoKvXr1woULFySs+B8NGzYsVbsgCJgxYwYA09nmhw8fxtChQ6HRaCAIAnbu3Gk0vyLbWKvVYtasWXB2doZSqcSwYcOQlJQkae06nQ7z589Hq1atoFQqodFoMGnSJCQnJxuto1evXqV+Ds8884yktQMV+36Y4nYHUOb3XhAEfPDBB4Y+Umz3ivwulOL7zpCuJlu2bEFoaChef/11REVFoXv37hg4cCASEhKkLs1IREQEZsyYgRMnTuDAgQMoLi5GcHAw8vLyjPoNGDAAKSkphunXX3+VqGJjLVu2NKorJibGMG/58uVYsWIFVq1ahVOnTkGtVqNfv36GsdmldOrUKaO6Dxw4AAB4+umnDX1MYZvn5eUhICAAq1atKnN+RbZxaGgoduzYgc2bN+Po0aPIzc3FkCFDUFJSIlnt+fn5iIyMxJtvvonIyEhs374dV65cwbBhw0r1feGFF4x+Dl988UW11l1e7X8r7/thitsdgFHNKSkpWLt2LQRBwKhRo4z61fR2r8jvQkm+7yJVi44dO4rTp083amvWrJm4YMECiSqqmLS0NBGAGBERYWgLCQkRhw8fLl1RD7Bo0SIxICCgzHl6vV5Uq9Xi+++/b2grLCwU7ezsxM8//7yGKqy4V155RWzcuLGo1+tFUTTNbQ5A3LFjh+F1RbZxZmamKJfLxc2bNxv63Lx5U5TJZOLevXslq70sJ0+eFAGIN27cMLT17NlTfOWVV6q3uHKUVXt534/atN2HDx8u9unTx6jNFLb7/b8Lpfq+c0+6GhQVFeHMmTMIDg42ag8ODsaxY8ckqqpisrKyAACOjo5G7eHh4XB1dYWfnx9eeOEFpKWlSVFeKXFxcdBoNPDx8cEzzzyDa9euAQDi4+ORmppq9DNQKBTo2bOnyf0MioqK8O233+K5554zeqCLqW7zv1VkG585cwY6nc6oj0ajgb+/v8n9HLKysiAIAuzt7Y3av/vuOzg7O6Nly5aYO3euSRyJAR7+/agt2/3WrVvYvXs3pkyZUmqe1Nv9/t+FUn3f+YCNanDnzh2UlJTAzc3NqN3NzQ2pqakSVVU+URQxe/ZsdOvWDf7+/ob2gQMH4umnn4a3tzfi4+Px5ptvok+fPjhz5oykowV16tQJ33zzDfz8/HDr1i289957CAoKwoULFwzbuayfwY0bN6Qo94F27tyJzMxMTJ482dBmqtv83yqyjVNTU2FhYQEHB4dSfUzp/0JhYSEWLFiAcePGGT0wYfz48fDx8YFarcb58+excOFCnD171nB6QirlfT9qy3bfsGEDVCoVRo4cadQu9XYv63ehVN93hnQ1uv8xl6IoVvrRl9Vp5syZOHfuHI4ePWrUPmbMGMO//f390b59e3h7e2P37t2l/nPVpIEDBxr+3apVK3Tp0gWNGzfGhg0bDBfR1IafwZo1azBw4EBoNBpDm6lu87I8zjY2pZ+DTqfDM888A71ej88++8xo3gsvvGD4t7+/P3x9fdG+fXtERkaibdu2NV2qweN+P0xpuwPA2rVrMX78eFhaWhq1S73dH/S7EKj57zsPd1cDZ2dnmJmZlfrLKS0trdRfYaZi1qxZ2LVrF8LCwsp9TKe7uzu8vb0RFxdXQ9VVjFKpRKtWrRAXF2e4ytvUfwY3btzAwYMH8fzzzz+0nylu84psY7VajaKiImRkZDywj5R0Oh1Gjx6N+Ph4HDhwoNzHDrZt2xZyudykfg5A6e+HqW93ADhy5AhiY2PL/e4DNbvdH/S7UKrvO0O6GlhYWKBdu3alDs0cOHAAQUFBElVVNlEUMXPmTGzfvh2HDh2Cj49Pucukp6cjMTER7u7uNVBhxWm1Wly6dAnu7u6GQ2X//hkUFRUhIiLCpH4G69atg6urKwYPHvzQfqa4zSuyjdu1awe5XG7UJyUlBefPn5f85/B3QMfFxeHgwYNwcnIqd5kLFy5Ap9OZ1M8BKP39MOXt/rc1a9agXbt2CAgIKLdvTWz38n4XSvZ9f6zLzahcmzdvFuVyubhmzRrx4sWLYmhoqKhUKsXr169LXZqRF198UbSzsxPDw8PFlJQUw5Sfny+Koijm5OSIc+bMEY8dOybGx8eLYWFhYpcuXcQGDRqI2dnZktY+Z84cMTw8XLx27Zp44sQJcciQIaJKpTJs4/fff1+0s7MTt2/fLsbExIhjx44V3d3dJa/7byUlJaKXl5c4f/58o3ZT2uY5OTliVFSUGBUVJQIQV6xYIUZFRRmugK7INp4+fbro4eEhHjx4UIyMjBT79OkjBgQEiMXFxZLVrtPpxGHDhokeHh5idHS00Xdfq9WKoiiKV69eFd9++23x1KlTYnx8vLh7926xWbNmYmBgoKS1V/T7YYrb/W9ZWVmitbW1uHr16lLLS7Xdy/tdKIrSfN8Z0tXo008/Fb29vUULCwuxbdu2Rrc1mQoAZU7r1q0TRVEU8/PzxeDgYNHFxUWUy+Wil5eXGBISIiYkJEhbuCiKY8aMEd3d3UW5XC5qNBpx5MiR4oULFwzz9Xq9uGjRIlGtVosKhULs0aOHGBMTI2HFxvbt2ycCEGNjY43aTWmbh4WFlfn9CAkJEUWxYtu4oKBAnDlzpujo6ChaWVmJQ4YMqZHP8rDa4+PjH/jdDwsLE0VRFBMSEsQePXqIjo6OooWFhdi4cWPx5ZdfFtPT0yWtvaLfD1Pc7n/74osvRCsrKzEzM7PU8lJt9/J+F4qiNN93PqqSiIjIRPGcNBERkYliSBMREZkohjQREZGJYkgTERGZKIY0ERGRiWJIExERmSiGNBERkYliSBMREZkohjQRSUYQBOzcuVPqMohMFkOaqJ6aPHkyBEEoNQ0YMEDq0ojoL3yeNFE9NmDAAKxbt86oTaFQSFQNEd2Pe9JE9ZhCoYBarTaaHBwcANw7FL169WoMHDgQVlZW8PHxwQ8//GC0fExMDPr06QMrKys4OTlh6tSpyM3NNeqzdu1atGzZEgqFAu7u7pg5c6bR/Dt37uDJJ5+EtbU1fH19sWvXrur90ES1CEOaiB7ozTffxKhRo3D27FlMmDABY8eOxaVLlwAA+fn5GDBgABwcHHDq1Cn88MMPOHjwoFEIr169GjNmzMDUqVMRExODXbt2oUmTJkbv8fbbb2P06NE4d+4cBg0ahPHjx+Pu3bs1+jmJTNZjPz+LiGq1kJAQ0czMTFQqlUbTO++8I4rivUf3TZ8+3WiZTp06iS+++KIoiqL45Zdfig4ODmJubq5h/u7du0WZTCampqaKoiiKGo1GfP311x9YAwDxjTfeMLzOzc0VBUEQ9+zZU2Wfk6g24zlponqsd+/eWL16tVGbo6Oj4d9dunQxmtelSxdER0cDAC5duoSAgAAolUrD/K5du0Kv1yM2NhaCICA5ORl9+/Z9aA2tW7c2/FupVEKlUiEtLe1xPxJRncKQJqrHlEplqcPP5REEAQAgiqLh32X1sbKyqtD65HJ5qWX1ev0j1URUV/GcNBE90IkTJ0q9btasGQCgRYsWiI6ORl5enmH+77//DplMBj8/P6hUKjRs2BC//fZbjdZMVJdwT5qoHtNqtUhNTTVqMzc3h7OzMwDghx9+QPv27dGtWzd89913OHnyJNasWQMAGD9+PBYtWoSQkBAsXrwYt2/fxqxZszBx4kS4ubkBABYvXozp06fD1dUVAwcORE5ODn7//XfMmjWrZj8oUS3FkCaqx/bu3Qt3d3ejtqZNm+Ly5csA7l15vXnzZrz00ktQq9X47rvv0KJFCwCAtbU19u3bh1deeQUdOnSAtbU1Ro0ahRUrVhjWFRISgsLCQqxcuRJz586Fs7MznnrqqZr7gES1nCCKoih1EURkegRBwI4dOzBixAipSyGqt3hOmoiIyEQxpImIiEwUz0kTUZl4JoxIetyTJiIiMlEMaSIiIhPFkCYiIjJRDGkiIiITxZAmIiIyUQxpIiIiE8WQJiIiMlEMaSIiIhPFkCYiIjJRDGkiIiITxZAmIiIyUQxpIiIiE8WQJiIiMlEMaSIiIhPFkCaqYYIgVGgKDw+v1PssXrwYgiA81rLh4eFVUgMRVY4g8qGxRDXqxIkTRq/fffddhIWF4dChQ0btLVq0gK2t7WO/T1JSEpKSktC5c+dHXjY7OxsXL16sdA1EVDkMaSKJTZ48GT/++CNyc3Mf2i8/Px/W1tY1VBURmQIe7iYyQb169YK/vz8OHz6MoKAgWFtb47nnngMAbNmyBcHBwXB3d4eVlRWaN2+OBQsWIC8vz2gdZR3ubtiwIYYMGYK9e/eibdu2sLKyQrNmzbB27VqjfmUd7p48eTJsbGxw9epVDBo0CDY2NvD09MScOXOg1WqNlk9KSsJTTz0FlUoFe3t7jB8/HqdOnYIgCFi/fv1DP/v69eshCAIOHTqEF154AU5OTrC1tcWkSZOQl5eH1NRUjB49Gvb29nB3d8fcuXOh0+mM1vH222+jU6dOcHR0hK2tLdq2bYs1a9agrH2SLVu2oEuXLlAqlbCxsUH//v0RFRX10BqJagpDmshEpaSkYMKECRg3bhx+/fVXvPTSSwCAuLg4DBo0CGvWrMHevXsRGhqKrVu3YujQoRVa79mzZzFnzhy8+uqr+Omnn9C6dWtMmTIFhw8fLndZnU6HYcOGoW/fvvjpp5/w3HPPYeXKlVi2bJmhT15eHnr37o2wsDAsW7YMW7duhZubG8aMGfNIn//555+HnZ0dNm/ejDfeeAPff/89XnjhBQwePBgBAQH48ccfERISgv/973/45JNPjJa9fv06pk2bhq1bt2L79u0YOXIkZs2ahXfffdeo35IlSzB27Fi0aNECW7duxcaNG5GTk4Pu3bvj4sWLj1QvUbUQiUhSISEholKpNGrr2bOnCED87bffHrqsXq8XdTqdGBERIQIQz549a5i3aNEi8f7/4t7e3qKlpaV448YNQ1tBQYHo6OgoTps2zdAWFhYmAhDDwsKM6gQgbt261WidgwYNEps2bWp4/emnn4oAxD179hj1mzZtmghAXLdu3UM/07p160QA4qxZs4zaR4wYIQIQV6xYYdTepk0bsW3btg9cX0lJiajT6cR33nlHdHJyEvV6vSiKopiQkCCam5uXep+cnBxRrVaLo0ePfmidRDWBe9JEJsrBwQF9+vQp1X7t2jWMGzcOarUaZmZmkMvl6NmzJwDg0qVL5a63TZs28PLyMry2tLSEn58fbty4Ue6ygiCU2mNv3bq10bIRERFQqVQYMGCAUb+xY8eWu/5/GzJkiNHr5s2bAwAGDx5cqv3+2g8dOoQnnngCdnZ2hm301ltvIT09HWlpaQCAffv2obi4GJMmTUJxcbFhsrS0RM+ePXllO5kEc6kLIKKyubu7l2rLzc1F9+7dYWlpiffeew9+fn6wtrZGYmIiRo4ciYKCgnLX6+TkVKpNoVBUaFlra2tYWlqWWrawsNDwOj09HW5ubqWWLavtYRwdHY1eW1hYPLD93+9/8uRJBAcHo1evXvjqq6/g4eEBCwsL7Ny5E//9738Nn/PWrVsAgA4dOpT5/jIZ92FIegxpIhNV1j3Ohw4dQnJyMsLDww17zwCQmZlZg5U9nJOTE06ePFmqPTU1tUbef/PmzZDL5fjll1+M/qDYuXOnUT9nZ2cAwI8//ghvb+8aqY3oUTGkiWqRv4NboVAYtX/xxRdSlFOmnj17YuvWrdizZw8GDhxoaN+8eXONvL8gCDA3N4eZmZmhraCgABs3bjTq179/f5ibm+PPP//EqFGjaqQ2okfFkCaqRYKCguDg4IDp06dj0aJFkMvl+O6773D27FmpSzMICQnBypUrMWHCBLz33nto0qQJ9uzZg3379gGo/sPIgwcPxooVKzBu3DhMnToV6enp+L//+79Sf9g0bNgQ77zzDl5//XVcu3YNAwYMgIODA27duoWTJ09CqVTi7bffrtZaicrDky5EtYiTkxN2794Na2trTJgwAc899xxsbGywZcsWqUszUCqVOHToEHr16oV58+Zh1KhRSEhIwGeffQYAsLe3r9b379OnD9auXYuYmBgMHToUr7/+Op566iksWLCgVN+FCxfixx9/xJUrVxASEoL+/ftj3rx5uHHjBnr06FGtdRJVBEccI6IasWTJErzxxhtISEiAh4eH1OUQ1Qo83E1EVW7VqlUAgGbNmkGn0+HQoUP4+OOPMWHCBAY00SNgSBNRlbO2tsbKlStx/fp1aLVaeHl5Yf78+XjjjTekLo2oVuHhbiIiIhPFC8eIiIhMFEOaiIjIRDGkiYiITBQvHCuDXq9HcnIyVCpVmUMzEhERVYYoisjJyYFGo3noAD8M6TIkJyfD09NT6jKIiKiOS0xMfOhtiQzpMqhUKgD3Np6tra3E1RARUV2TnZ0NT09PQ948CEO6DH8f4ra1tWVIExFRtSnvlCovHCMiIjJRDGkiIiITxZAmIiIyUQxpIiIiE8WQJiIiMlEM6Wq2bO9l7D2fInUZRERUCzGkq9He86lYHf4nXvwuEhuPX5e6HCIiqmUY0tXoieauGNvRC6IIvPnTBXzyW5zUJRERUS3CkK5G5mYyLHnSH68+4QcA+N+BK/gp+qbEVRERUW3BkK5mgiDglSd8Mb1nYwDAaz+eQ3RiprRFERFRrcCQriGv9W+KJ5q7oqhYj1mbIpGnLZa6JCIiMnEM6RpiJhOwckwbNLC3QuLdAiz59ZLUJRERkYljSNcglaUcHzzVGgDw3R8JPD9NREQPxZCuYUFNnDE5qCEA4JXN0Vj003loi0ukLYqIiEwSQ1oCrw9ujmk9GwEANhy/gVGrj+H6nTyJqyIiIlPDkJaA3EyGhQObY93kDnCwluP8zWwM/eQoziVlSl0aERGZEIa0hHo3c8Wvr3RHO28H5GiL8cI3p3Eru1DqsoiIyEQwpCXmbmeF9c92QBNXG9zK1mLqxjMo1PEcNRERMaRNgspSjjUh7WFvLcfZxEws5e1ZREQEhrTJ8HZSYuWYNgDuXUy2J4ZPziIiqu8Y0iakd1NXw1Xf87adQ0pWgcQVERGRlBjSJmZucFMEeNojp7AY8348B1EUpS6JiIgkImlIL126FB06dIBKpYKrqytGjBiB2NhYoz6iKGLx4sXQaDSwsrJCr169cOHChXLXvW3bNrRo0QIKhQItWrTAjh07qutjVCm5mQz/ezoACnMZjsTdwadhV5FTqJO6LCIikoCkIR0REYEZM2bgxIkTOHDgAIqLixEcHIy8vH8G9li+fDlWrFiBVatW4dSpU1Cr1ejXrx9ycnIeuN7jx49jzJgxmDhxIs6ePYuJEydi9OjR+OOPP2riY1VaE1cbvNa/KQDg//ZfQeA7B/Bp2FWJqyIiopomiCZ0PPX27dtwdXVFREQEevToAVEUodFoEBoaivnz5wMAtFot3NzcsGzZMkybNq3M9YwZMwbZ2dnYs2ePoW3AgAFwcHDApk2byq0jOzsbdnZ2yMrKgq2tbdV8uEdUohfxadhV7Ii6ifg7eRAEYNuLQWjr5SBJPUREVHUqmjMmdU46KysLAODo6AgAiI+PR2pqKoKDgw19FAoFevbsiWPHjj1wPcePHzdaBgD69+//wGW0Wi2ys7ONJqmZyQS83NcXYXN7YVRbD4gi8J/tMdCV6KUujYiIaojJhLQoipg9eza6desGf39/AEBqaioAwM3Nzaivm5ubYV5ZUlNTH2mZpUuXws7OzjB5enpW5qNUudcHN4eDtRyXU3Mw+ovj+Pi3OGQV8Dw1EVFdZzIhPXPmTJw7d67Mw9GCIBi9FkWxVFtlllm4cCGysrIMU2Ji4iNWX70clRZ4e7g/ZAIQlZCJFQeuIGTtSRQUcWQyIqK6zCRCetasWdi1axfCwsLg4eFhaFer1QBQag84LS2t1J7yv6nV6kdaRqFQwNbW1mgyNcMCNDg0pxfeG+EPOys5ohMzMWtTFIp5+JuIqM6SNKRFUcTMmTOxfft2HDp0CD4+PkbzfXx8oFarceDAAUNbUVERIiIiEBQU9MD1dunSxWgZANi/f/9Dl6kNGjorMaGzN9aEtIeFuQwHL93C10fjpS6LiIiqiaQhPWPGDHz77bf4/vvvoVKpkJqaitTUVBQU3BtpSxAEhIaGYsmSJdixYwfOnz+PyZMnw9raGuPGjTOsZ9KkSVi4cKHh9SuvvIL9+/dj2bJluHz5MpYtW4aDBw8iNDS0pj9itWjf0BHvDb933v6T3+L45CwiojpK0pBevXo1srKy0KtXL7i7uxumLVu2GPrMmzcPoaGheOmll9C+fXvcvHkT+/fvh0qlMvRJSEhASso/Y10HBQVh8+bNWLduHVq3bo3169djy5Yt6NSpU41+vur0VDsPBHrZI6+ohA/kICKqo0zqPmlTYQr3SVdETFIWhn16FKIILHmyFcZ18pK6JCIiqoBaeZ80PZpWHnaY2v3eAzn+syOGo5IREdUxDOlabsHAZpjZuwkA4IN9sdgZdVPiioiIqKowpGs5QRAwt39TQ1D/Z0cMrqY9eFxzIiKqPRjSdcSr/fwQ1NgJ+UUleOm7SOQXFUtdEhERVRJDuo4wkwn46JlAuKgUuHIrF2/9VP7jPImIyLQxpOsQF5UCHz8TCJkA/HgmCVtOJUhdEhERVQJDuo7p0tgJs/v5AQAWbI/B10eugXfZERHVTgzpOuilXk0wtqMXRBF4b/clLNp1AXo9g5qIqLZhSNdBMpmAJU/6443BzSEIwDfHb+C1H8/xYRxERLUMQ7qOEgQBz3dvhJWj28BMJmBbZBIWbI/hoW8iolqEIV3HjQhsgE/H/XMx2SeHOCoZEVFtwZCuBwb4u+Odv56ateLAFfxwOlHiioiIqCIY0vXEhM7emNbj3jjf87edw+5zKeUsQUREUmNI1yMLBjbDMx08oReBVzZH4dDlW1KXRERED8GQrkcEQcB/n2yFYQEaFOtFTP82Er9fvSN1WURE9AAM6XrGTCbgf6MD0K+FG4qK9Xh+w2lcu50rdVlERFQGhnQ9JDeTYdW4QHTycUSBrgRL91yWuiQiIioDQ7qeUpib4b9P+sNMJuDAxVs49icPexMRmRqGdD3WxFWF8Z28AADv/nIJBUUlEldERET/xpCu50Kf8IOtpTkupWTjmS+P43aOVuqSiIjoLwzpes5RaYG1kzvAwVqOs0lZGPjRYXx95BoKddyrJiKSmqQhffjwYQwdOhQajQaCIGDnzp1G8wVBKHP64IMPHrjO9evXl7lMYWFhNX+a2qt9Q0dsf6krGrsocSe3CO/tvoRRq48hV1ssdWlERPWapCGdl5eHgIAArFq1qsz5KSkpRtPatWshCAJGjRr10PXa2tqWWtbS0rI6PkKd4eOsxN7QHnh/ZCs4Ki1wITkbM76L5JOziIgkZC7lmw8cOBADBw584Hy1Wm30+qeffkLv3r3RqFGjh65XEIRSy1L55GYyPNPRC83cbfHMl8cRceU2XtkSjQ+eag1rC0m/KkRE9VKtOSd969Yt7N69G1OmTCm3b25uLry9veHh4YEhQ4YgKiqqBiqsO9p42uPjZwJhJhOw+1wKRnz6OxLv5ktdFhFRvVNrQnrDhg1QqVQYOXLkQ/s1a9YM69evx65du7Bp0yZYWlqia9euiIuLe+AyWq0W2dnZRlN9F9xSjU0vdIaLSoErt3Ixa1MU9Ho+i5qIqCbVmpBeu3Ytxo8fX+655c6dO2PChAkICAhA9+7dsXXrVvj5+eGTTz554DJLly6FnZ2dYfL09Kzq8muljj6O2DmjK2wU5ohOzMRWPuKSiKhG1YqQPnLkCGJjY/H8888/8rIymQwdOnR46J70woULkZWVZZgSExlGf2tgb4XQJ3wBAO/vvYw7ubyPmoioptSKkF6zZg3atWuHgICAR15WFEVER0fD3d39gX0UCgVsbW2NJvrH5KCGaKZWITNfh+GrfsfJ+LtSl0REVC9IGtK5ubmIjo5GdHQ0ACA+Ph7R0dFISEgw9MnOzsYPP/zwwL3oSZMmYeHChYbXb7/9Nvbt24dr164hOjoaU6ZMQXR0NKZPn16tn6UuMzeT4eOxgfB2ssbNzAI88+VxfHvihtRlERHVeZKG9OnTpxEYGIjAwEAAwOzZsxEYGIi33nrL0Gfz5s0QRRFjx44tcx0JCQlISUkxvM7MzMTUqVPRvHlzBAcH4+bNmzh8+DA6duxYvR+mjvNzU2H3y90xMrAB9CLwxs7z+OS3OIgiLyYjIqougsjfsqVkZ2fDzs4OWVlZPPR9H1EUsfJgHD7+7d45/kVDW+DZrj4SV0VEVLtUNGdqxTlpMh2CIGB2Pz/MG9AUAPDuLxdx6PItiasiIqqbGNL0WF7s2Rhj2ntCLwIzvotCWGya1CUREdU5DGl6LIIg4N0R/ujh54ICXQme33Ca91ETEVUxhjQ9NgtzGb6e1B4j2zZAiV7Ef7bH4GIyR2sjIqoqDGmqFAtzGf73dAAGtFSjWC9i/rZzfHIWEVEVYUhTpQmCgHdGtIStpTlibmbhqyPxUpdERFQnMKSpSriqLPH64OYAgOX7LmPzyYRyliAiovIwpKnKjG7viZAu3hBFYMH2GLz7y0Xcyi6UuiwiolqLIU1VRhAELB7WEi90vze4yZqj8ei+LIxXfRMRPSaGNFUpQRDwn0HNsXZye7T3dkBRiR4Lt8fg96t3pC6NiKjWYUhTlRMEAX2aueGH6V0woo0GJXoRL357BvF38qQujYioVmFIU7URBAHvj2qNtl72yC4sxszvI6EtLpG6LCKiWoMhTdXKUm6Gz8a3g721HBeSs7F8byyfnEVEVEEMaap2ajtLfPBUAIB7F5N1XPIbXvvhLHIKdRJXRkRk2hjSVCP6tXDD7H5+MJcJuJ2jxQ9nkhCy9iSyGdRERA/EkKYa83JfX5x/uz/WPdsBdlZyRCZk4tl1p1Ci5+FvIqKyMKSpRlnKzdC7qSu+e74TVApznLmRgbDLfMwlEVFZGNIkCf8GdhjXyQsAsOH4dWmLISIyUQxpksyEzt4QBOBI3B38eTtX6nKIiEwOQ5ok4+lojb7NXAEAXx+5Bj3PTRMRGWFIk6RCghoCADadTMQTKyOw/0KqtAUREZkQSUP68OHDGDp0KDQaDQRBwM6dO43mT548GYIgGE2dO3cud73btm1DixYtoFAo0KJFC+zYsaOaPgFVVrcmzpjdzw8qhTmu3c7DtG/PYOspPpCDiAiQOKTz8vIQEBCAVatWPbDPgAEDkJKSYph+/fXXh67z+PHjGDNmDCZOnIizZ89i4sSJGD16NP7444+qLp+qgCAIeLmvL47/py/GdvSEKALztp3DRwfjoCvRS10eEZGkBNFExmgUBAE7duzAiBEjDG2TJ09GZmZmqT3shxkzZgyys7OxZ88eQ9uAAQPg4OCATZs2VWgd2dnZsLOzQ1ZWFmxtbSv83lQ5oijivd2XsOZoPACgmVqFz8a3RSMXG4krIyKqWhXNGZM/Jx0eHg5XV1f4+fnhhRdeQFraw++pPX78OIKDg43a+vfvj2PHjlVnmVQFBEHAG4Ob48MxbeBgLcfl1By89F0kioq5R01E9ZO51AU8zMCBA/H000/D29sb8fHxePPNN9GnTx+cOXMGCoWizGVSU1Ph5uZm1Obm5obU1AdfkKTVaqHVag2vs7Ozq+YD0CMTBAEjAhugS2MnDPzoCC6n5mDlwSvo2NAR6XlFeDKwAcxkgtRlEhHVCJMO6TFjxhj+7e/vj/bt28Pb2xu7d+/GyJEjH7icIBj/EhdFsVTbvy1duhRvv/125QumKuNma4l3h/tjxveRWB3+J1bjTwBAwt18zO7nJ3F1REQ147EPd2/cuBFdu3aFRqPBjRs3AAAffvghfvrppyor7n7u7u7w9vZGXFzcA/uo1epSe81paWml9q7/beHChcjKyjJMiYm8utgUDG7tjicDGwAAnJQWAIBPDsXh2J93pCyLiKjGPFZIr169GrNnz8agQYOQmZmJkpISAIC9vT0+/PDDqqzPSHp6OhITE+Hu7v7APl26dMGBAweM2vbv34+goKAHLqNQKGBra2s0kWn4v6cD8Nucnjj1+hMY3d4Dogi8uiUad/OKpC6NiKjaPVZIf/LJJ/jqq6/w+uuvw8zMzNDevn17xMTEVHg9ubm5iI6ORnR0NAAgPj4e0dHRSEhIQG5uLubOnYvjx4/j+vXrCA8Px9ChQ+Hs7Iwnn3zSsI5JkyZh4cKFhtevvPIK9u/fj2XLluHy5ctYtmwZDh48iNDQ0Mf5qCQxM5mAxi42kMkELB7WEo1dlLiVrcXcH87CRG5MICKqNo8V0vHx8QgMDCzVrlAokJeXV+H1nD59GoGBgYZ1zZ49G4GBgXjrrbdgZmaGmJgYDB8+HH5+fggJCYGfnx+OHz8OlUplWEdCQgJSUlIMr4OCgrB582asW7cOrVu3xvr167FlyxZ06tTpcT4qmRBrC3OsGtcWFuYyHLqcZrhVi4iornqsC8d8fHwQHR0Nb29vo/Y9e/agRYsWFV5Pr169Hro3tG/fvnLXER4eXqrtqaeewlNPPVXhOqj2aO5uizcHN8ebP13A0j2X4eFgjQH+aqnLIiKqFo8V0q+99hpmzJiBwsJCiKKIkydPYtOmTVi6dCm+/vrrqq6RyMiEzt6ITszCtsgkzNoUifdHtsbQAA0szE3+tn8iokfy2COOffXVV3jvvfcMV0I3aNAAixcvxpQpU6q0QClwxDHTV6IXEbolGj+fTQYA2FvL8ebgFhjVzkPiyoiIylfRnKn0sKB37tyBXq+Hq6trZVZjUhjStUNxiR4f/RaHzacScTtHC4W5DGFze0FjbyV1aURED1Vjw4I6OzvXqYCm2sPcTIY5wU1xYmFfdPJxhLZYj//bFyt1WUREVeaxRxz78ccfsXXrViQkJKCoyPie1cjIyEoXRlRRZjIBrw9ujmGrfsf2qJt4tqsPWnnYSV0WEVGlPdae9Mcff4xnn30Wrq6uiIqKQseOHeHk5IRr165h4MCBVV0jUblae9gbRiebtSkSadmFEldERFR5jxXSn332Gb788kusWrUKFhYWmDdvHg4cOICXX34ZWVlZVV0jUYUsHNQMno5WuJ6ej/Ff/4FDl2/hTq62/AWJiEzUY4V0QkKCYZhNKysr5OTkAAAmTpxY4Wc2E1U1V5Ulvn++M9S2lohLy8Vz60+j27JD+P0qx/omotrpsUJarVYjPT0dAODt7Y0TJ04AuDcSGYdqJCl5Olpjy7TOeKqdB7wcrVGo0+PdXy5Cr+f3kohqn8cK6T59+uDnn38GAEyZMgWvvvoq+vXrhzFjxhiNq00kBW8nJf7v6QD8PLMbVJbmuJyag19iUspfkIjIxDzWfdJ6vR56vR7m5vcuDv/hhx9w5MgRNGnSBC+++CLkcnmVF1qTeJ903fHJb3H434EraOSsxP5Xe8DcjKOSEZH0qvU+aZlMhuLiYpw8eRK//PILFAoFnnjiCTRs2BB79+597KKJqtqz3XzgqLTAtTt5WH/sutTlEBE9kse6T3rv3r2YOHGi4bz0vwmCYHi+NJHUbBTmmNe/KRZsj8H/7Y9FvxZuKNCVwEZhDg8Ha6nLIyJ6qMfak545cyZGjx6NlJQUw6HvvycGNJmaMR080aWREwp1egz48AgGfHgEAz88gsS7+VKXRkT0UI8V0mlpaZg9ezbc3Nyquh6iKicIAt4f1QqWchkKdPf+iMzRFmPO1rMo4VXfRGTCHiukn3rqqTKf40xkqrydlNgytQs+HNMGv8zqBqWFGU5ev4tley8jV1ssdXlERGV6rKu78/Pz8fTTT8PFxQWtWrUqdTX3yy+/XGUFSoFXd9d9m08mYMH2GACAtYUZ3hrSAs909JK4KiKqLyqaM4914dj333+Pffv2wcrKCuHh4RAEwTBPEIRaH9JU943p4Am9CHx99Bqu3c7DW7suoHMjJzR0VkpdGhGRwWPtSavVarz88stYsGABZLK6d98p96TrD1EUMWntSRyJu4PeTV2wdnIHoz86iYiqQ7XeJ11UVIQxY8bUyYCm+kUQBCwe1hJyMwFhsbcxdeMZLP31EtL5YA4iMgGPlbIhISHYsmVLVddCJInGLjZ4vnsjAMCBi7fwxeFrmLUpiuPQE5HkHuucdElJCZYvX459+/ahdevWpS4cW7FiRZUUR1RT5vTzQwt3W9zKLsT/7Y/FsT/TsflUIsbyYjIiktBj7UnHxMQgMDAQMpkM58+fR1RUlGGKjo6u8HoOHz6MoUOHQqPRQBAE7Ny50zBPp9Nh/vz5aNWqFZRKJTQaDSZNmoTk5OSHrnP9+vUQBKHUVFhY+DgfleoJczMZhgZo8Hz3Rpgb3BQA8N/dlxAWm8Y9aiKSzGPtSYeFhVXJm+fl5SEgIADPPvssRo0aZTQvPz8fkZGRePPNNxEQEICMjAyEhoZi2LBhOH369EPXa2tri9jYWKM2S0vLKqmZ6r5nu/rg15gURCZk4tl1p9DWyx5fTGwPF5VC6tKIqJ55rJCuKgMHDsTAgQPLnGdnZ4cDBw4YtX3yySfo2LEjEhIS4OX14MOQgiBArVZXaa1Uf5jJBKyd3AGrDl3Ft3/cQGRCJl745jQ2T+0MS7mZ1OURUT1Sqy7PzsrKgiAIsLe3f2i/3NxceHt7w8PDA0OGDEFUVNRD+2u1WmRnZxtNVL/ZW1vgjSEtsPvl7rCzkiM6MROvbolGcYle6tKIqB6pNSFdWFiIBQsWYNy4cQ+9p6xZs2ZYv349du3ahU2bNsHS0hJdu3ZFXFzcA5dZunQp7OzsDJOnp2d1fASqhRq72ODLie0gNxOw53wqXtkSDR2DmohqyGMNZlIdBEHAjh07MGLEiFLzdDodnn76aSQkJCA8PPyRBhjR6/Vo27YtevTogY8//rjMPlqtFlrtP/fFZmdnw9PTk4OZkMG+C6mY+X0kdCUi+jRzxYrRAbC3tpC6LCKqpap1MJOapNPpMHr0aMTHx+PAgQOPHJoymQwdOnR46J60QqGAra2t0UT0b/1bqvHlxPawMJfh0OU0DProCE5fvyt1WURUx5l0SP8d0HFxcTh48CCcnJweeR2iKCI6Ohru7u7VUCHVJ72buWLb9CA0dLJGclYhxn51AjujbkpdFhHVYZKGdG5uLqKjow33VsfHxyM6OhoJCQkoLi7GU089hdOnT+O7775DSUkJUlNTkZqaiqKiIsM6Jk2ahIULFxpev/3229i3bx+uXbuG6OhoTJkyBdHR0Zg+fXpNfzyqg1p52OGXl7tjoL8auhIRoVui8fWRa1KXRUR1lKS3YJ0+fRq9e/c2vJ49ezaAe8OOLl68GLt27QIAtGnTxmi5sLAw9OrVCwCQkJBgNIZ4ZmYmpk6ditTUVNjZ2SEwMBCHDx9Gx44dq/fDUL1hozDHp+Pa4v29l/Hl4Wt4b/cluKgUGN6mgdSlEVEdYzIXjpkSPgWLKurdXy5izdF4WJjJ8M2Ujujc6NFPyRBR/VNnLhwjMmWvD2qOgf5qFJXoMfWb07ialiN1SURUhzCkiSpBJhOwckwbtPWyR3ZhMULWnkJKVoHUZRFRHcGQJqokS7kZvg7pgIZO1riZWYBhq37n7VlEVCUY0kRVwFFpgY1TOqGpmwq3c7QY+9UJ7D2fKnVZRFTLMaSJqoinozW2vxRkuD1r1qZI/HbpltRlEVEtxpAmqkJKhTk+GRuIIa3doSsR8fw3pzH68+P4+ezDn4NORFQWSe+TJqqLzM1kWDmmDSzMZNgedRMnr9/Fyet3obI0R6+mrlKXR0S1CPekiaqB3EyGFWPa4PcFffBk4L1BTl7fcR652mKJKyOi2oQhTVSNGthb4b9P+sPT0Qo3Mwswf9s5JGfyFi0iqhiGNFE1s7Ywx/sjWwMAdp9LQbdlh/DuLxfBwf6IqDwMaaIa0LWJM9ZObo/OjRyhF4E1R+PxyaGrUpdFRCaOIU1UQ/o0c8PmqV3w3yf9AQArDlzB1tOJEldFRKaMIU1Uw8Z38sb0no0BAAu2ncOvMSkSV0REpoohTSSBef2bYnR7D+hF4OVNUVixPxZJGflSl0VEJoYhTSQBmUzA0pGtMSxAg2K9iI8PXUXPD8Kx7UyS1KURkQlhSBNJxOyvJ2h99EwbdPRxRIlexPxt53Ds6h2pSyMiEyGIvA+klIo+jJuoquj1Il7ZEo2fzybDUi6Dj7MNWjeww1tDW0Cp4MCARHVNRXOG//uJTIBMJuCDp1rjVnYhTsbfxaWUbFxKyUZ2oQ6fjmsLmUyQukQikgAPdxOZCEu5GTa90Bk/zeiKlWMCYGEmw57zqfj4UJzUpRGRRLgnTWRCzGQCAjztEeBpD12xiHnbzuHDg3EoLhExJ9gPgsA9aqL6hHvSRCZqdAdPvPqEHwBgVdhVLNgWw6FEieoZSUP68OHDGDp0KDQaDQRBwM6dO43mi6KIxYsXQ6PRwMrKCr169cKFCxfKXe+2bdvQokULKBQKtGjRAjt27KimT0BUvV55whfLRrWCmUzAltOJ+OrINalLIqIaJGlI5+XlISAgAKtWrSpz/vLly7FixQqsWrUKp06dglqtRr9+/ZCTk/PAdR4/fhxjxozBxIkTcfbsWUycOBGjR4/GH3/8UV0fg6hajenghcVDWwAA3t9zGRFXbktcERHVFJO5BUsQBOzYsQMjRowAcG8vWqPRIDQ0FPPnzwcAaLVauLm5YdmyZZg2bVqZ6xkzZgyys7OxZ88eQ9uAAQPg4OCATZs2VagW3oJFpkYURSzYFoMtpxNhbWGGjVM6op23o9RlEdFjqmjOmOw56fj4eKSmpiI4ONjQplAo0LNnTxw7duyByx0/ftxoGQDo37//Q5fRarXIzs42mohMiSAIeGdES3Rr4oz8ohKErD2F/RdSodebxN/YRFRNTDakU1NTAQBubm5G7W5uboZ5D1ruUZdZunQp7OzsDJOnp2clKieqHgpzM3w16d7jLnO1xZi68QyeWBnBEcqI6jCTDem/3X/LiSiK5d6G8qjLLFy4EFlZWYYpMZGPDyTTZGVhhjUhHTCtRyOoFOa4djsPE9eexPrf41GoK5G6PCKqYiYb0mq1GgBK7QGnpaWV2lO+f7lHXUahUMDW1tZoIjJVSoU5Fg5qjuP/6YsnAxugRC9i8c8X0XLRPoxafQw3MwukLpGIqojJhrSPjw/UajUOHDhgaCsqKkJERASCgoIeuFyXLl2MlgGA/fv3P3QZotrIRmGOFaMD8Pqg5nBSWqBEL+LMjQy89O0ZaIu5V01UF0g64lhubi6uXr1qeB0fH4/o6Gg4OjrCy8sLoaGhWLJkCXx9feHr64slS5bA2toa48aNMywzadIkNGjQAEuXLgUAvPLKK+jRoweWLVuG4cOH46effsLBgwdx9OjRGv98RNVNEAS80KMRnu/ug6tpuXj6i+M4m5SFt3++iCVPtpK6PCKqJEn3pE+fPo3AwEAEBgYCAGbPno3AwEC89dZbAIB58+YhNDQUL730Etq3b4+bN29i//79UKlUhnUkJCQgJSXF8DooKAibN2/GunXr0Lp1a6xfvx5btmxBp06davbDEdUgQRDg66bCh2PaQBCA7/9IwLcnbkhdFhFVksncJ21KeJ801Wafhl3FB/tiYfbXk7WauNrAz00FS7mZ1KUR0V/4qEqieuqlXo3xZ1outkfdxOytZwEADeytsHFKRzRysZG4OiJ6FCZ74RgRPR5BELB0VCuMbu8BbydrqCzNcTOzAKO/OI5LKRyoh6g24eHuMvBwN9Uld3K1mLTmJC6mZMNFpcCOl4Lg4WAtdVlE9VqtHxaUiKqGs40Cm6Z2RjO1CrdztHhu/SkcjbuD09fvclhRIhPHkCaqB+ys5Fg7uQNcVQpcuZWLCWv+wFOfH8eSXy9JXRoRPQRDmqie0NhbYf2zHdGlkRP83O5dQPb10Xgc+5NjfxOZKoY0UT3SQmOLTVM7Y/+rPTGukxcAYO7WsziXlAlenkJkehjSRPXU64Oaw9vJGslZhRi26ncM+vgort3OlbosIvoXhjRRPaVUmGPDsx0xNEADhbkMl1KyMfqLE7icytu0iEwFQ5qoHmvorMQnYwNxdH4fNHe3xZ1cLUZ/fhy7ziZLXRoRgSFNRABcVApsfqEz2nk7ILuwGC9visKz605i34VUFBXrpS6PqN7iYCZl4GAmVF/pSvT4NOwqPjl0FSV/3UPdwN4Kc4L90N3XBRbmMthZySWukqj2q2jOMKTLwJCm+i7uVg5+OJOEHVE3cTtHazTvlb6+eLWfn0SVEdUNHHGMiB6br5sK/xnUHEfm9cZr/ZvCwfqfvedPDsUhMiFDwuqI6g/uSZeBe9JEZXt1SzR2RN1EIxclPp/QDp4O1rCy4CMwiR4V96SJqMotGtoCLioFrt3OQ/DKw2jzzn6sDv/TcP6aiKoW96TLwD1pogc7c+Mu3vnlEq7dzkVOYTEAoJGLElZyMzR0UuLNIS2gtrOUuEoi08YLxyqBIU1UPlEU8cPpJLz98wXkFZUY2p2UFlg5pg16+LlIWB2RaWNIVwJDmqjiUrMKEZWQAZlMwEcH43AxJRuCAMzq3QSvPOEHM5kgdYlEJochXQkMaaLHU6grwTu/XMT3fyQAAIIaO+HjsYFwtlFIXBmRaeGFY0RU4yzlZljyZCt89EwbWFuY4dif6Rj6yVHsv5CK4hKOXEb0qEw+pBs2bAhBEEpNM2bMKLN/eHh4mf0vX75cw5UT1V/D2zTATzO6opGLEilZhZi68Qy6LjuE/9sXi4T0fKnLI6o1zKUuoDynTp1CSck/F6WcP38e/fr1w9NPP/3Q5WJjY40OIbi48CIWoprk66bCTzO6YtWhq/jhTBJuZWuxKuwqVoVdxZDW7ujb3BXfnUjAnVwtVo1rC/8GdlKXTGRyat056dDQUPzyyy+Ii4uDIJS+ICU8PBy9e/dGRkYG7O3tH+s9eE6aqGoVFetx8NItbD6ViMNXbpeab6Mwx9ch7dG5kZME1RHVvDp5TrqoqAjffvstnnvuuTID+t8CAwPh7u6Ovn37Iiws7KF9tVotsrOzjSYiqjoW5jIMauWOb57riN0vd8MTzd3g5WiN6T0bo5OPI3K1xRj31Qm89sNZJGcWSF0ukcmoVXvSW7duxbhx45CQkACNRlNmn9jYWBw+fBjt2rWDVqvFxo0b8fnnnyM8PBw9evQoc5nFixfj7bffLtXOPWmi6leoK8H8befwU/S9Z1jbKMzx3yf9MbxNA4krI6o+dfIWrP79+8PCwgI///zzIy03dOhQCIKAXbt2lTlfq9VCq/3nST/Z2dnw9PRkSBPVoMiEDLz3y0VEJmQCAFxVCsgEAUFNnDClmw9auNuWewSNqLaoaEib/IVjf7tx4wYOHjyI7du3P/KynTt3xrfffvvA+QqFAgoF7+MkklJbLwdsndYFHx+6ik8OxSHtr0dkbo+8ie2RN2GjMIevmw3eGtICgV4OEldLVDNqTUivW7cOrq6uGDx48CMvGxUVBXd392qoioiqkrmZDLP7+WF8Jy/cztEiu1CH7/9IwN7zqcjVFiMqIRMTvv4DHz0TiBJRhNLCHF2bOHEPm+qsWhHSer0e69atQ0hICMzNjUteuHAhbt68iW+++QYA8OGHH6Jhw4Zo2bKl4UKzbdu2Ydu2bVKUTkSPwc3WEm629x7SEdTYGYW6EiRl5GPRrgv4/Wo6nv/mtKHv8DYavD+yNR+ZSXVSrQjpgwcPIiEhAc8991ypeSkpKUhISDC8Lioqwty5c3Hz5k1YWVmhZcuW2L17NwYNGlSTJRNRFbKUm6GJqwprQjpg5vdR+O3yLTRxsUH8nTz8FJ2Mk/F30bmREwb4qxHcwo171lRn1KoLx2oK75MmMl2iKEJbrIel3AwnrqVj5veRuJNbZJjf3dcZ743wh7eTEnq9iMSMfHg5WjO4yaTUyau7awpDmqj2yNMW4/SNDByNu40Nx2+gqFgPpYUZZgc3xZ6YFJy+kYFBrdRYOaYNFOY8JE6mgSFdCQxpotop/k4e5m87h5Pxd0vN6+Hngv89HQAnpQXCr6Qhv6gEg1u5cw+bJMGQrgSGNFHtVaIX8VnYVXwSdhXdmjhjaIA7/rP9PAp0JbAwl0FjZ4nrfz3kY26wH2b28YUoijhw8RbW/X4dnRs5YWafJnwOtkROXb+LXG0xevm5VNkfUFkFOqgU5pCZ0M+UIV0JDGmi2q+4RA9zs3sjH59NzMTiny8g6q+BUqzkZijQ3Xtwz8jABoi9lYMLyf8MBxzU2AnPdvWBu50lmrjawFJeOw6T/3k7Fyfj76JDQ0c0cbUpNT9XWwyFuQxyMxl0JXqcjL8LB2sLNHS2xtG4O4i5mQUnpQUaOivRpbETzGUyHL16B3vPp+LYn3fg6WCNuf2boo2nPURRxIXkbJxNykR7b0c0VasM7yOKIo5fS8eGY9eRqy2GfwM79PB1QZdGThAE4MqtXGyLTEJ0Yia6NnbGoFZqpOVosf7YdRy4eAvAvSMf8wc0RTO1LXILi3E+OQvX7uQhLbsQTVxt4G5nhV1nb+L8zWw42yggNxNw7XYebuUUIrewGL5uKkzv2QhH4u7gxzNJaOqmwqy+TRDgYQ97azlUlnKjbZNfVIzT1zPwR3w67K0sMCTAHe52VgCAtOxC/HwuBQLujYjX1tseTVxVqAyGdCUwpInqHlEUcep6BpIy8tG3uRs+j/gTq8P/NMy3lMswPKABfj6XjPyif568Zy4ToLG3QlaBDpZyGab2aIwJnb1Knd/OyCuCrZX8oXvghboS3MwsQE5hMRrYW8FFdW8Qpds5WtzJ1SK/qAQ2ins33Rz/8w7u5uvwdDsPeDpaG5bfdTYZ+y/cwvE/76BLYyd89EwgivUiPjoYh2+OX0ex/t6v9HbeDpjZ514obTuThD3nUxCVmAlHawuEBDXEnvOpuJTy4OcUqCzNYSU3Mwwq829utgroxXt1/62pmwrdfJ1hozDH3vOpiL2VU+ZyRcV6ZOTrHvi+ZjIBZoKAor+eP25hLkNRcdU/i9zHWYnGLkpkFxYjObMANzML8O80FASgk48j2nk74JvjN5BTWGyYt2hoCzzb1adS78+QrgSGNFHdJ4oiPgv/EylZBWjj6YAefs5wVVnialoOPvrtKm6k5yEpowB384pKLauyNEdDJyUa2FtBbWeJU9fv4kJyNnyclVgwsBlSswrxR3w6BEGAldwMlnIZUjILcfTqHWj/Chy5mYDhbRrgVnYhjsTdeWCdFmYy9PdXQwBwJO52qYBr6qbC7Vytoc5mahXi0nJR8ldYywRA/4Df8iqFOUTc28PW2FmiaxNnw6AxqdmFAAAHazkGt3ZHD18X7LtwC9ujkgxhZimXwV9jh7NJmdCVGL+JwlyG0e090VJji8iEDOw9n4rsv4JObiagp58rgho7YXdMCs4lZaKBvRX8G9jhlb6+MJMJ+O/uSzj2Z7rhiIeXozX83GzgbKPAheRs3EjPQ8+mrujXwg1ZBToUFevRyFmJBg5WUJjL8OOZJKz7/Toau9rgteCmOHX9LrZFJiE9t8iwzvupbS0R1MQJSXcLcPK68XUNLTW2aORig9xCHSYFNUTvpq4P/JlVBEO6EhjSRATcC/KUrEIk3s2Hg9ICZ25kYOWBK2XuXVaUjcIcSoUZbmX/sw5BAJyUClhZyJBbWAxtsR6BXvYo0Ys4cc04LDwcrDCmvSeauNrg9Z3nDeHs62qDN4e0QA8/F6RlF+KrI9fwzfEb0Bbr0aqBHUZ38EQvPxf8fvUO1v4eD/8GdvjPoOZwsLZAWk4h1LaWhnPAer2IyIQM5GqL0aWxk9FRg7TsQqTlaKEt1qO5uwrWFubIytch/Eoa/oi/i6x8HXo2dUFwCzfYW1sYlivUleBk/F3YW8vRVK0yWqcoimWefy7Ri0jKyIetpRwOSotS88tTohfLPLKRla9DVGIGkjIKYGclh6tKgSauNnCy+Wd46JuZBdgVnYzT1++im68zJnVpWKXXKTCkK4EhTUQPUlSsx7U7uUi6W4CkjHwkZxXC09EavfxcsO736/jhTCIaudigf0s3WMnNUKjTo0BXAmsLM/T0c0EztQqCIODMjbvYeioJjjYWGNfRy3BI+99EUcSxP9MReSMDVhZm8HFWoldTV0NYXLudixUHrqBDQ0eM6+QFuZnx04fv5hUhu0CHhs7KGtk2VHEM6UpgSBMRUXWqaM7IHjiHiIiIJMWQJiIiMlEMaSIiIhPFkCYiIjJRDGkiIiITxZAmIiIyUQxpIiIiE2UudQGm6O9bx7OzHzyuLRER0eP6O1/KG6qEIV2GnJx7A8N7enpKXAkREdVlOTk5sLOze+B8jjhWBr1ej+TkZKhUqko/zzQ7Oxuenp5ITEysdaOX1dbaa2vdAGuXCmuvebW1bqBqahdFETk5OdBoNJDJHnzmmXvSZZDJZPDw8KjSddra2ta6L+LfamvttbVugLVLhbXXvNpaN1D52h+2B/03XjhGRERkohjSREREJoohXc0UCgUWLVoEhUJRfmcTU1trr611A6xdKqy95tXWuoGarZ0XjhEREZko7kkTERGZKIY0ERGRiWJIExERmSiGdDX67LPP4OPjA0tLS7Rr1w5HjhyRuqRSli5dig4dOkClUsHV1RUjRoxAbGysUZ/JkydDEASjqXPnzhJV/I/FixeXqkutVhvmi6KIxYsXQ6PRwMrKCr169cKFCxckrPgfDRs2LFW7IAiYMWMGANPZ5ocPH8bQoUOh0WggCAJ27txpNL8i21ir1WLWrFlwdnaGUqnEsGHDkJSUJGntOp0O8+fPR6tWraBUKqHRaDBp0iQkJycbraNXr16lfg7PPPOMpLUDFft+mOJ2B1Dm914QBHzwwQeGPlJs94r8LpTi+86QriZbtmxBaGgoXn/9dURFRaF79+4YOHAgEhISpC7NSEREBGbMmIETJ07gwIEDKC4uRnBwMPLy8oz6DRgwACkpKYbp119/lahiYy1btjSqKyYmxjBv+fLlWLFiBVatWoVTp05BrVajX79+hmFfpXTq1Cmjug8cOAAAePrppw19TGGb5+XlISAgAKtWrSpzfkW2cWhoKHbs2IHNmzfj6NGjyM3NxZAhQ1BSUiJZ7fn5+YiMjMSbb76JyMhIbN++HVeuXMGwYcNK9X3hhReMfg5ffPFFtdZdXu1/K+/7YYrbHYBRzSkpKVi7di0EQcCoUaOM+tX0dq/I70JJvu8iVYuOHTuK06dPN2pr1qyZuGDBAokqqpi0tDQRgBgREWFoCwkJEYcPHy5dUQ+waNEiMSAgoMx5er1eVKvV4vvvv29oKywsFO3s7MTPP/+8hiqsuFdeeUVs3LixqNfrRVE0zW0OQNyxY4fhdUW2cWZmpiiXy8XNmzcb+ty8eVOUyWTi3r17Jau9LCdPnhQBiDdu3DC09ezZU3zllVeqt7hylFV7ed+P2rTdhw8fLvbp08eozRS2+/2/C6X6vnNPuhoUFRXhzJkzCA4ONmoPDg7GsWPHJKqqYrKysgAAjo6ORu3h4eFwdXWFn58fXnjhBaSlpUlRXilxcXHQaDTw8fHBM888g2vXrgEA4uPjkZqaavQzUCgU6Nmzp8n9DIqKivDtt9/iueeeMxor3lS3+d8qso3PnDkDnU5n1Eej0cDf39/kfg5ZWVkQBAH29vZG7d999x2cnZ3RsmVLzJ071ySOxAAP/37Ulu1+69Yt7N69G1OmTCk1T+rtfv/vQqm+7xy7uxrcuXMHJSUlcHNzM2p3c3NDamqqRFWVTxRFzJ49G926dYO/v7+hfeDAgXj66afh7e2N+Ph4vPnmm+jTpw/OnDkj6UAEnTp1wjfffAM/Pz/cunUL7733HoKCgnDhwgXDdi7rZ3Djxg0pyn2gnTt3IjMzE5MnTza0meo2/7eKbOPU1FRYWFjAwcGhVB9T+r9QWFiIBQsWYNy4cUZjMY8fPx4+Pj5Qq9U4f/48Fi5ciLNnzxpOT0ilvO9HbdnuGzZsgEqlwsiRI43apd7uZf0ulOr7zpCuRvc/QUsUxUo/Vas6zZw5E+fOncPRo0eN2seMGWP4t7+/P9q3bw9vb2/s3r271H+umjRw4EDDv1u1aoUuXbqgcePG2LBhg+EimtrwM1izZg0GDhwIjUZjaDPVbV6Wx9nGpvRz0Ol0eOaZZ6DX6/HZZ58ZzXvhhRcM//b394evry/at2+PyMhItG3btqZLNXjc74cpbXcAWLt2LcaPHw9LS0ujdqm3+4N+FwI1/33n4e5q4OzsDDMzs1J/OaWlpZX6K8xUzJo1C7t27UJYWFi5TwBzd3eHt7c34uLiaqi6ilEqlWjVqhXi4uIMV3mb+s/gxo0bOHjwIJ5//vmH9jPFbV6RbaxWq1FUVISMjIwH9pGSTqfD6NGjER8fjwMHDpT7RKO2bdtCLpeb1M8BKP39MPXtDgBHjhxBbGxsud99oGa3+4N+F0r1fWdIVwMLCwu0a9eu1KGZAwcOICgoSKKqyiaKImbOnInt27fj0KFD8PHxKXeZ9PR0JCYmwt3dvQYqrDitVotLly7B3d3dcKjs3z+DoqIiREREmNTPYN26dXB1dcXgwYMf2s8Ut3lFtnG7du0gl8uN+qSkpOD8+fOS/xz+Dui4uDgcPHgQTk5O5S5z4cIF6HQ6k/o5AKW/H6a83f+2Zs0atGvXDgEBAeX2rYntXt7vQsm+7491uRmVa/PmzaJcLhfXrFkjXrx4UQwNDRWVSqV4/fp1qUsz8uKLL4p2dnZieHi4mJKSYpjy8/NFURTFnJwccc6cOeKxY8fE+Ph4MSwsTOzSpYvYoEEDMTs7W9La58yZI4aHh4vXrl0TT5w4IQ4ZMkRUqVSGbfz++++LdnZ24vbt28WYmBhx7Nixoru7u+R1/62kpET08vIS58+fb9RuSts8JydHjIqKEqOiokQA4ooVK8SoqCjDFdAV2cbTp08XPTw8xIMHD4qRkZFinz59xICAALG4uFiy2nU6nThs2DDRw8NDjI6ONvrua7VaURRF8erVq+Lbb78tnjp1SoyPjxd3794tNmvWTAwMDJS09op+P0xxu/8tKytLtLa2FlevXl1qeam2e3m/C0VRmu87Q7oaffrpp6K3t7doYWEhtm3b1ui2JlMBoMxp3bp1oiiKYn5+vhgcHCy6uLiIcrlc9PLyEkNCQsSEhARpCxdFccyYMaK7u7sol8tFjUYjjhw5Urxw4YJhvl6vFxctWiSq1WpRoVCIPXr0EGNiYiSs2Ni+fftEAGJsbKxRuylt87CwsDK/HyEhIaIoVmwbFxQUiDNnzhQdHR1FKysrcciQITXyWR5We3x8/AO/+2FhYaIoimJCQoLYo0cP0dHRUbSwsBAbN24svvzyy2J6erqktVf0+2GK2/1vX3zxhWhlZSVmZmaWWl6q7V7e70JRlOb7zqdgERERmSiekyYiIjJRDGkiIiITxZAmIiIyUQxpIiIiE8WQJiIiMlEMaSIiIhPFkCYiIjJRDGkiIiITxZAmIskIgoCdO3dKXQaRyWJIE9VTkydPhiAIpaYBAwZIXRoR/YXPkyaqxwYMGIB169YZtSkUComqIaL7cU+aqB5TKBRQq9VGk4ODA4B7h6JXr16NgQMHwsrKCj4+Pvjhhx+Mlo+JiUGfPn1gZWUFJycnTJ06Fbm5uUZ91q5di5YtW0KhUMDd3R0zZ840mn/nzh08+eSTsLa2hq+vL3bt2lW9H5qoFmFIE9EDvfnmmxg1ahTOnj2LCRMmYOzYsbh06RIAID8/HwMGDICDgwNOnTqFH374AQcPHjQK4dWrV2PGjBmYOnUqYmJisGvXLjRp0sToPd7+//bunqWVIArj+DNRC7OkUIJGKyuVFNooErSRVFoJik2QbaMQbOwUjH4ALQXBMiBYWAW1sAyIVbBRv4AEBRsjaJNzC2EhqPdFLnFj/j8IzM7sLmeqh90T2K0tLS4u6urqSrOzs8pkMnp8fGzoPoHQ+vL3swA0Nd/3ra2tzTzPq/ttb2+b2dun+7LZbN01ExMTtry8bGZm+/v71tXVZdVqNVgvFosWiUSsUqmYmVl/f7+tr69/WoMk29jYCI6r1ao55+zk5OS/7RNoZvSkgRY2PT2tvb29urnu7u5gnEql6tZSqZTK5bIk6fr6WqOjo/I8L1ifnJxUrVbT7e2tnHO6u7tTOp3+bQ0jIyPB2PM8xWIx3d/ff3VLwI9CSAMtzPO8d6+f/8Q5J0kys2D80TmdnZ1/db+Ojo5319ZqtX+qCfip6EkD+NTFxcW74+HhYUlSMplUuVzW8/NzsF4qlRSJRDQ4OKhYLKaBgQGdn583tGbgJ+FJGmhhr6+vqlQqdXPt7e2Kx+OSpKOjI42NjWlqakqFQkGXl5c6ODiQJGUyGW1ubsr3feXzeT08PCiXy2lpaUm9vb2SpHw+r2w2q56eHs3MzOjp6UmlUkm5XK6xGwWaFCENtLDT01P19fXVzQ0NDenm5kbS2z+vDw8PtbKyokQioUKhoGQyKUmKRqM6OzvT6uqqxsfHFY1GNT8/r52dneBevu/r5eVFu7u7WltbUzwe18LCQuM2CDQ5Z2b23UUACB/nnI6PjzU3N/fdpQAti540AAAhRUgDABBS9KQBfIhOGPD9eJIGACCkCGkAAEKKkAYAIKQIaQAAQoqQBgAgpAhpAABCipAGACCkCGkAAEKKkAYAIKR+ARAXn7C6ELNVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot the training history\n",
    "\n",
    "history_keys = history.history.keys()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(history_keys), figsize=(5,6))\n",
    "\n",
    "for i, key in enumerate(history_keys):\n",
    "    axes[i].plot(history.history[key])\n",
    "    axes[i].set_xlabel('Epoch')\n",
    "    axes[i].set_ylabel(key)\n",
    "    axes[i].set_title(f'Training {key}')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above how the loss (MSE), and our additional metric (MAE) change at each epoch.  We see a consistent slope downward until the model levels off at a certain point in the training.  The model has found either a local or global minimum for the loss landscape defined by the loss function and the model architecture.  \n",
    "\n",
    "**Note** By default Keras models start with randomized weights.  This means that your model's training history may not be exactly the same as this one.  It also means that your model metrics may be somewhat different as well.\n",
    "\n",
    "We may be able to find a lower minimum, i.e. lower loss, with a larger model, or maybe not.  Remember, all real world data contains irreducible loss and there will be a limit to how well our model can make predictions, no matter how complex we make it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model Test</th>\n",
       "      <td>83.05852</td>\n",
       "      <td>6.502083</td>\n",
       "      <td>9.113645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Train</th>\n",
       "      <td>83.74678</td>\n",
       "      <td>6.598583</td>\n",
       "      <td>9.151327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MSE       MAE      RMSE\n",
       "Model Test   83.05852  6.502083  9.113645\n",
       "Model Train  83.74678  6.598583  9.151327"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_regression(true, pred, name='model'):\n",
    "    df = pd.DataFrame(columns=['MSE', 'MAE', 'RMSE'], index=[name])\n",
    "    df['MAE'] = mean_absolute_error(true, pred)\n",
    "    df['MSE'] = mean_squared_error(true, pred)\n",
    "    df['RMSE'] = mean_squared_error(true, pred, squared=False)\n",
    "    return df\n",
    "\n",
    "test_scores = eval_regression(y_test, model.predict(X_test_sc), name='Model Test')\n",
    "train_scores = eval_regression(y_train, model.predict(X_train_sc), name='Model Train')\n",
    "\n",
    "scores = pd.concat([test_scores, train_scores])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning models can have a tendancy to overfit, especially when they become very large.  However, in this case our model has low variance.  This may indicate we could try a more complex models, either more layers or more nodes, but we will talk about that more in a later lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lesson you learned about how to make a simple regression model in Keras.  You installed TensorFlow and Keras 3, instantiated a `Sequential()` Keras model, and added appropriate `Input()` and `Dense()` layers, including an output layer with one node and no activation function.  Then you compiled the model with an appropriate loss function, MSE, and some additional metrics.  Finally, you fit your model on the training data, visualized the training history, and evaluated it with regression metrics.\n",
    "\n",
    "# Challenges:\n",
    "\n",
    "1. Try changing the number of nodes and layers of this model.  Can you create a model with a lower loss?\n",
    "2. Try increasing the model complexity and/or number of training metrics to see if you can create a model that overfits.\n",
    "3. Explore the [Keras Documentation](https://keras.io/api/) and see what other optimizers and activation functions are available. If you tune those, can you further improve your model? **Remember not to add any activation function to your final layer!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lesson-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
